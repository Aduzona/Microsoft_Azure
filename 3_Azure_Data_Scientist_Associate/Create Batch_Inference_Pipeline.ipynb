{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.42.0 to work with ml-lab-s534vtqj735ae\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1655929388312
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and register a model\r\n",
        "\r\n",
        "Now let's train and register a model to deploy in a batch inferencing pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.core import Model\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "\r\n",
        "# Create an Azure ML experiment in your workspace\r\n",
        "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\r\n",
        "run = experiment.start_logging()\r\n",
        "print(\"Starting experiment:\", experiment.name)\r\n",
        "\r\n",
        "# load the diabetes dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "diabetes = pd.read_csv('data/diabetes.csv')\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "# Train a decision tree model\r\n",
        "print('Training a decision tree model')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# Save the trained model\r\n",
        "model_file = 'diabetes_model.pkl'\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\r\n",
        "\r\n",
        "# Complete the run\r\n",
        "run.complete()\r\n",
        "\r\n",
        "# Register the model\r\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\r\n",
        "                   tags={'Training context':'Inline Training'},\r\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\r\n",
        "\r\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: mslearn-train-diabetes\nLoading Data...\nTraining a decision tree model\nAccuracy: 0.891\nAUC: 0.8763943479775113\nModel trained and registered.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655927080350
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate and upload batch data\r\n",
        "Since we don't actually have a fully staffed clinic with patients from whom to get new data for this exercise, you'll generate a random sample from our diabetes CSV file, upload that data to a datastore in the Azure Machine Learning workspace, and register a dataset for it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "# Set default data store\r\n",
        "ws.set_default_datastore('workspaceblobstore')\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastores, indicating which is the default\r\n",
        "for ds_name in ws.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\r\n",
        "\r\n",
        "# Load the diabetes data\r\n",
        "diabetes = pd.read_csv('data/diabetes2.csv')\r\n",
        "# Get a 100-item sample of the feature columns (not the diabetic label)\r\n",
        "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\r\n",
        "\r\n",
        "# Create a folder\r\n",
        "batch_folder = './batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "# Save each sample as a separate file\r\n",
        "print(\"Saving files...\")\r\n",
        "for i in range(100):\r\n",
        "    fname = str(i+1) + '.csv'\r\n",
        "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\r\n",
        "print(\"files saved!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspaceworkingdirectory - Default = False\nworkspaceblobstore - Default = True\nworkspaceartifactstore - Default = False\nworkspacefilestore - Default = False\nFolder created!\nSaving files...\nfiles saved!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655927479235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\r\n",
        "#Dataset.File.upload_directory(src_dir, target, pattern=None, overwrite=False, show_progress=True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \r\n",
        "                                             name='batch-data',\r\n",
        "                                             description='batch data',\r\n",
        "                                             create_new_version=True)\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading files to datastore...\nUploading an estimated of 102 files\nUploading batch-data/.amlignore\nUploaded batch-data/.amlignore, 1 files out of an estimated total of 102\nUploading batch-data/.amlignore.amltmp\nUploaded batch-data/.amlignore.amltmp, 2 files out of an estimated total of 102\nUploading batch-data/1.csv\nUploaded batch-data/1.csv, 3 files out of an estimated total of 102\nUploading batch-data/10.csv\nUploaded batch-data/10.csv, 4 files out of an estimated total of 102\nUploading batch-data/100.csv\nUploaded batch-data/100.csv, 5 files out of an estimated total of 102\nUploading batch-data/11.csv\nUploaded batch-data/11.csv, 6 files out of an estimated total of 102\nUploading batch-data/12.csv\nUploaded batch-data/12.csv, 7 files out of an estimated total of 102\nUploading batch-data/13.csv\nUploaded batch-data/13.csv, 8 files out of an estimated total of 102\nUploading batch-data/14.csv\nUploaded batch-data/14.csv, 9 files out of an estimated total of 102\nUploading batch-data/15.csv\nUploaded batch-data/15.csv, 10 files out of an estimated total of 102\nUploading batch-data/16.csv\nUploaded batch-data/16.csv, 11 files out of an estimated total of 102\nUploading batch-data/17.csv\nUploaded batch-data/17.csv, 12 files out of an estimated total of 102\nUploading batch-data/18.csv\nUploaded batch-data/18.csv, 13 files out of an estimated total of 102\nUploading batch-data/19.csv\nUploaded batch-data/19.csv, 14 files out of an estimated total of 102\nUploading batch-data/2.csv\nUploaded batch-data/2.csv, 15 files out of an estimated total of 102\nUploading batch-data/20.csv\nUploaded batch-data/20.csv, 16 files out of an estimated total of 102\nUploading batch-data/21.csv\nUploaded batch-data/21.csv, 17 files out of an estimated total of 102\nUploading batch-data/22.csv\nUploaded batch-data/22.csv, 18 files out of an estimated total of 102\nUploading batch-data/23.csv\nUploaded batch-data/23.csv, 19 files out of an estimated total of 102\nUploading batch-data/24.csv\nUploaded batch-data/24.csv, 20 files out of an estimated total of 102\nUploading batch-data/25.csv\nUploaded batch-data/25.csv, 21 files out of an estimated total of 102\nUploading batch-data/26.csv\nUploaded batch-data/26.csv, 22 files out of an estimated total of 102\nUploading batch-data/27.csv\nUploaded batch-data/27.csv, 23 files out of an estimated total of 102\nUploading batch-data/28.csv\nUploaded batch-data/28.csv, 24 files out of an estimated total of 102\nUploading batch-data/29.csv\nUploaded batch-data/29.csv, 25 files out of an estimated total of 102\nUploading batch-data/3.csv\nUploaded batch-data/3.csv, 26 files out of an estimated total of 102\nUploading batch-data/30.csv\nUploaded batch-data/30.csv, 27 files out of an estimated total of 102\nUploading batch-data/31.csv\nUploaded batch-data/31.csv, 28 files out of an estimated total of 102\nUploading batch-data/32.csv\nUploaded batch-data/32.csv, 29 files out of an estimated total of 102\nUploading batch-data/33.csv\nUploaded batch-data/33.csv, 30 files out of an estimated total of 102\nUploading batch-data/34.csv\nUploaded batch-data/34.csv, 31 files out of an estimated total of 102\nUploading batch-data/35.csv\nUploaded batch-data/35.csv, 32 files out of an estimated total of 102\nUploading batch-data/36.csv\nUploaded batch-data/36.csv, 33 files out of an estimated total of 102\nUploading batch-data/37.csv\nUploaded batch-data/37.csv, 34 files out of an estimated total of 102\nUploading batch-data/38.csv\nUploaded batch-data/38.csv, 35 files out of an estimated total of 102\nUploading batch-data/39.csv\nUploaded batch-data/39.csv, 36 files out of an estimated total of 102\nUploading batch-data/4.csv\nUploaded batch-data/4.csv, 37 files out of an estimated total of 102\nUploading batch-data/40.csv\nUploaded batch-data/40.csv, 38 files out of an estimated total of 102\nUploading batch-data/41.csv\nUploaded batch-data/41.csv, 39 files out of an estimated total of 102\nUploading batch-data/42.csv\nUploaded batch-data/42.csv, 40 files out of an estimated total of 102\nUploading batch-data/43.csv\nUploaded batch-data/43.csv, 41 files out of an estimated total of 102\nUploading batch-data/44.csv\nUploaded batch-data/44.csv, 42 files out of an estimated total of 102\nUploading batch-data/45.csv\nUploaded batch-data/45.csv, 43 files out of an estimated total of 102\nUploading batch-data/46.csv\nUploaded batch-data/46.csv, 44 files out of an estimated total of 102\nUploading batch-data/47.csv\nUploaded batch-data/47.csv, 45 files out of an estimated total of 102\nUploading batch-data/48.csv\nUploaded batch-data/48.csv, 46 files out of an estimated total of 102\nUploading batch-data/49.csv\nUploaded batch-data/49.csv, 47 files out of an estimated total of 102\nUploading batch-data/50.csv\nUploaded batch-data/50.csv, 48 files out of an estimated total of 102\nUploading batch-data/51.csv\nUploaded batch-data/51.csv, 49 files out of an estimated total of 102\nUploading batch-data/52.csv\nUploaded batch-data/52.csv, 50 files out of an estimated total of 102\nUploading batch-data/53.csv\nUploaded batch-data/53.csv, 51 files out of an estimated total of 102\nUploading batch-data/54.csv\nUploaded batch-data/54.csv, 52 files out of an estimated total of 102\nUploading batch-data/55.csv\nUploaded batch-data/55.csv, 53 files out of an estimated total of 102\nUploading batch-data/56.csv\nUploaded batch-data/56.csv, 54 files out of an estimated total of 102\nUploading batch-data/5.csv\nUploaded batch-data/5.csv, 55 files out of an estimated total of 102\nUploading batch-data/57.csv\nUploaded batch-data/57.csv, 56 files out of an estimated total of 102\nUploading batch-data/58.csv\nUploaded batch-data/58.csv, 57 files out of an estimated total of 102\nUploading batch-data/59.csv\nUploaded batch-data/59.csv, 58 files out of an estimated total of 102\nUploading batch-data/6.csv\nUploaded batch-data/6.csv, 59 files out of an estimated total of 102\nUploading batch-data/60.csv\nUploaded batch-data/60.csv, 60 files out of an estimated total of 102\nUploading batch-data/61.csv\nUploaded batch-data/61.csv, 61 files out of an estimated total of 102\nUploading batch-data/62.csv\nUploaded batch-data/62.csv, 62 files out of an estimated total of 102\nUploading batch-data/63.csv\nUploaded batch-data/63.csv, 63 files out of an estimated total of 102\nUploading batch-data/64.csv\nUploaded batch-data/64.csv, 64 files out of an estimated total of 102\nUploading batch-data/65.csv\nUploaded batch-data/65.csv, 65 files out of an estimated total of 102\nUploading batch-data/66.csv\nUploaded batch-data/66.csv, 66 files out of an estimated total of 102\nUploading batch-data/67.csv\nUploaded batch-data/67.csv, 67 files out of an estimated total of 102\nUploading batch-data/68.csv\nUploaded batch-data/68.csv, 68 files out of an estimated total of 102\nUploading batch-data/69.csv\nUploaded batch-data/69.csv, 69 files out of an estimated total of 102\nUploading batch-data/7.csv\nUploaded batch-data/7.csv, 70 files out of an estimated total of 102\nUploading batch-data/70.csv\nUploaded batch-data/70.csv, 71 files out of an estimated total of 102\nUploading batch-data/71.csv\nUploaded batch-data/71.csv, 72 files out of an estimated total of 102\nUploading batch-data/72.csv\nUploaded batch-data/72.csv, 73 files out of an estimated total of 102\nUploading batch-data/73.csv\nUploaded batch-data/73.csv, 74 files out of an estimated total of 102\nUploading batch-data/74.csv\nUploaded batch-data/74.csv, 75 files out of an estimated total of 102\nUploading batch-data/75.csv\nUploaded batch-data/75.csv, 76 files out of an estimated total of 102\nUploading batch-data/76.csv\nUploaded batch-data/76.csv, 77 files out of an estimated total of 102\nUploading batch-data/77.csv\nUploaded batch-data/77.csv, 78 files out of an estimated total of 102\nUploading batch-data/78.csv\nUploaded batch-data/78.csv, 79 files out of an estimated total of 102\nUploading batch-data/79.csv\nUploaded batch-data/79.csv, 80 files out of an estimated total of 102\nUploading batch-data/8.csv\nUploaded batch-data/8.csv, 81 files out of an estimated total of 102\nUploading batch-data/80.csv\nUploaded batch-data/80.csv, 82 files out of an estimated total of 102\nUploading batch-data/81.csv\nUploaded batch-data/81.csv, 83 files out of an estimated total of 102\nUploading batch-data/82.csv\nUploaded batch-data/82.csv, 84 files out of an estimated total of 102\nUploading batch-data/83.csv\nUploaded batch-data/83.csv, 85 files out of an estimated total of 102\nUploading batch-data/84.csv\nUploaded batch-data/84.csv, 86 files out of an estimated total of 102\nUploading batch-data/85.csv\nUploaded batch-data/85.csv, 87 files out of an estimated total of 102\nUploading batch-data/86.csv\nUploaded batch-data/86.csv, 88 files out of an estimated total of 102\nUploading batch-data/87.csv\nUploaded batch-data/87.csv, 89 files out of an estimated total of 102\nUploading batch-data/88.csv\nUploaded batch-data/88.csv, 90 files out of an estimated total of 102\nUploading batch-data/89.csv\nUploaded batch-data/89.csv, 91 files out of an estimated total of 102\nUploading batch-data/9.csv\nUploaded batch-data/9.csv, 92 files out of an estimated total of 102\nUploading batch-data/90.csv\nUploaded batch-data/90.csv, 93 files out of an estimated total of 102\nUploading batch-data/91.csv\nUploaded batch-data/91.csv, 94 files out of an estimated total of 102\nUploading batch-data/92.csv\nUploaded batch-data/92.csv, 95 files out of an estimated total of 102\nUploading batch-data/93.csv\nUploaded batch-data/93.csv, 96 files out of an estimated total of 102\nUploading batch-data/94.csv\nUploaded batch-data/94.csv, 97 files out of an estimated total of 102\nUploading batch-data/95.csv\nUploaded batch-data/95.csv, 98 files out of an estimated total of 102\nUploading batch-data/96.csv\nUploaded batch-data/96.csv, 99 files out of an estimated total of 102\nUploading batch-data/97.csv\nUploaded batch-data/97.csv, 100 files out of an estimated total of 102\nUploading batch-data/98.csv\nUploaded batch-data/98.csv, 101 files out of an estimated total of 102\nUploading batch-data/99.csv\nUploaded batch-data/99.csv, 102 files out of an estimated total of 102\nUploaded 102 files\nDone!\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655929590938
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"automl-compute\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        inference_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655929787410
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a pipeline for batch inferencing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the experiment files\r\n",
        "experiment_folder = 'batch_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "batch_pipeline\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655929849421
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_diabetes.py\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Model\r\n",
        "import joblib\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    # Runs when the pipeline step is initialized\r\n",
        "    global model\r\n",
        "\r\n",
        "    # load the model\r\n",
        "    model_path = Model.get_model_path('diabetes_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        # Read the comma-delimited data into an array\r\n",
        "        data = np.genfromtxt(f, delimiter=',')\r\n",
        "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\r\n",
        "        prediction = model.predict(data.reshape(1, -1))\r\n",
        "        # Append prediction to results\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing batch_pipeline/batch_diabetes.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline will need an environment in which to run, so we'll create a Conda specification that includes the packages that the code uses."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_environment.yml\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing batch_pipeline/batch_environment.yml\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll define a run context that includes the Conda environment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655930453122
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a ParallelRunStep, which enables the batch data to be processed in parallel and the results collated in a single output file named parallel_run_step.txt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory=experiment_folder,\r\n",
        "    entry_script=\"batch_diabetes.py\",\r\n",
        "    mini_batch_size=\"5\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=batch_env,\r\n",
        "    compute_target=inference_cluster,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-score-diabetes',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\r\n",
        "    output=output_dir,\r\n",
        "    arguments=[],\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655930586243
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to put the step into a pipeline, and run it.\r\n",
        "\r\n",
        "Note: This may take some time!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-diabetes [5dd9d453][f0f258cc-51a1-41cd-9397-8d8115ac90a9], (This step will run and generate new outputs)\nSubmitted PipelineRun a1f73378-9987-44a9-8a9e-1411755519f4\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/a1f73378-9987-44a9-8a9e-1411755519f4?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-983-32/workspaces/ml-lab-s534vtqj735ae&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipelineRunId: a1f73378-9987-44a9-8a9e-1411755519f4\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/a1f73378-9987-44a9-8a9e-1411755519f4?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-983-32/workspaces/ml-lab-s534vtqj735ae&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 227bf318-7aad-4e00-8bc3-16793e06a13c\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/227bf318-7aad-4e00-8bc3-16793e06a13c?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-983-32/workspaces/ml-lab-s534vtqj735ae&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nStepRun( batch-score-diabetes ) Status: NotStarted\nStepRun( batch-score-diabetes ) Status: Queued\nStepRun( batch-score-diabetes ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2022/06/22 20:45:40 Downloading source code...\n2022/06/22 20:45:41 Finished downloading source code\n2022/06/22 20:45:41 Creating Docker network: acb_default_network, driver: 'bridge'\n2022/06/22 20:45:41 Successfully set up Docker network: acb_default_network\n2022/06/22 20:45:41 Setting up Docker configuration...\n2022/06/22 20:45:42 Successfully set up Docker configuration\n2022/06/22 20:45:42 Logging in to registry: 6ac408498dd5400ab41e98d2029b838f.azurecr.io\n2022/06/22 20:45:43 Successfully logged into 6ac408498dd5400ab41e98d2029b838f.azurecr.io\n2022/06/22 20:45:43 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/06/22 20:45:43 Scanning for dependencies...\n2022/06/22 20:45:43 Successfully scanned dependencies\n2022/06/22 20:45:43 Launching container with name: acb_step_0\nSending build context to Docker daemon  66.56kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220504.v1@sha256:2fe35e84ab983f66478e9c2bc19e07121719283ada745bbb846209aca8530c8f\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220504.v1@sha256:2fe35e84ab983f66478e9c2bc19e07121719283ada745bbb846209aca8530c8f: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd5fd17ec1767: Pulling fs layer\nc7ce926c7707: Pulling fs layer\nb6527ed3eb0f: Pulling fs layer\n7f5e079fa1c7: Pulling fs layer\nd82d9722257b: Pulling fs layer\n2bf166919eca: Pulling fs layer\n0b2c99241754: Pulling fs layer\n7aa47c332fd6: Pulling fs layer\n374285ba860b: Pulling fs layer\n7f5e079fa1c7: Waiting\nd82d9722257b: Waiting\n2bf166919eca: Waiting\n0b2c99241754: Waiting\n7aa47c332fd6: Waiting\n374285ba860b: Waiting\nd5fd17ec1767: Verifying Checksum\nd5fd17ec1767: Download complete\nb6527ed3eb0f: Verifying Checksum\nb6527ed3eb0f: Download complete\n7f5e079fa1c7: Verifying Checksum\n7f5e079fa1c7: Download complete\n2bf166919eca: Verifying Checksum\n2bf166919eca: Download complete\nd82d9722257b: Verifying Checksum\nd82d9722257b: Download complete\nc7ce926c7707: Verifying Checksum\nc7ce926c7707: Download complete\n7aa47c332fd6: Verifying Checksum\n7aa47c332fd6: Download complete\n0b2c99241754: Verifying Checksum\n0b2c99241754: Download complete\n374285ba860b: Verifying Checksum\n374285ba860b: Download complete\nd5fd17ec1767: Pull complete\nc7ce926c7707: Pull complete\nb6527ed3eb0f: Pull complete\n7f5e079fa1c7: Pull complete\nd82d9722257b: Pull complete\n2bf166919eca: Pull complete\n0b2c99241754: Pull complete\n7aa47c332fd6: Pull complete\n374285ba860b: Pull complete\nDigest: sha256:2fe35e84ab983f66478e9c2bc19e07121719283ada745bbb846209aca8530c8f\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220504.v1@sha256:2fe35e84ab983f66478e9c2bc19e07121719283ada745bbb846209aca8530c8f\n ---> 19ea84283b95\nStep 2/21 : USER root\n ---> Running in b7484890133b\nRemoving intermediate container b7484890133b\n ---> 80b780318a4a\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in a17a2594e538\nRemoving intermediate container a17a2594e538\n ---> 94ae6dc38dca\nStep 4/21 : WORKDIR /\n ---> Running in 2b610c1cc519\nRemoving intermediate container 2b610c1cc519\n ---> 24f93da5b8a0\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> be919d86fdd9\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in 1e6ece9f5ff8\nRemoving intermediate container 1e6ece9f5ff8\n ---> f03c558bb863\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> c77205f2d361\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 53e61480d02b\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nzlib-1.2.12          | 106 KB    |            |   0% \nzlib-1.2.12          | 106 KB    | #5         |  15% \nzlib-1.2.12          | 106 KB    | ########## | 100% \n\nsqlite-3.23.1        | 808 KB    |            |   0% \nsqlite-3.23.1        | 808 KB    | #####1     |  51% \nsqlite-3.23.1        | 808 KB    | ########## | 100% \n\nca-certificates-2022 | 124 KB    |            |   0% \nca-certificates-2022 | 124 KB    | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\nmkl_fft-1.3.0        | 170 KB    |            |   0% \nmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n\nlibedit-3.1          | 151 KB    |            |   0% \nlibedit-3.1          | 151 KB    | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\nnumpy-base-1.19.2    | 4.1 MB    |            |   0% \nnumpy-base-1.19.2    | 4.1 MB    | #7         |  17% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \nnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\nsetuptools-58.0.4    | 788 KB    |            |   0% \nsetuptools-58.0.4    | 788 KB    | ########## | 100% \n\nscikit-learn-0.24.2  | 5.2 MB    |            |   0% \nscikit-learn-0.24.2  | 5.2 MB    | ######4    |  65% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \nscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\nopenssl-1.0.2u       | 2.2 MB    |            |   0% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \nopenssl-1.0.2u       | 2.2 MB    | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########8  |  88% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\nintel-openmp-2022.0. | 4.2 MB    |            |   0% \nintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \nintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \n\nscipy-1.5.2          | 14.4 MB   |            |   0% \nscipy-1.5.2          | 14.4 MB   | ##6        |  26% \nscipy-1.5.2          | 14.4 MB   | ########8  |  89% \nscipy-1.5.2          | 14.4 MB   | ########## | 100% \n\nnumpy-1.19.2         | 22 KB     |            |   0% \nnumpy-1.19.2         | 22 KB     | ########## | 100% \n\nmkl-service-2.3.0    | 52 KB     |            |   0% \nmkl-service-2.3.0    | 52 KB     | ########## | 100% \n\nreadline-7.0         | 848 KB    |            |   0% \nreadline-7.0         | 848 KB    | ########## | 100% \n\ncertifi-2021.5.30    | 139 KB    |            |   0% \ncertifi-2021.5.30    | 139 KB    | ########## | 100% \n\nlibffi-3.2.1         | 48 KB     |            |   0% \nlibffi-3.2.1         | 48 KB     | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\njoblib-1.0.1         | 208 KB    |            |   0% \njoblib-1.0.1         | 208 KB    | ########## | 100% \n\npython-3.6.2         | 23.6 MB   |            |   0% \npython-3.6.2         | 23.6 MB   | ##         |  21% \npython-3.6.2         | 23.6 MB   | #####7     |  58% \npython-3.6.2         | 23.6 MB   | #########4 |  94% \npython-3.6.2         | 23.6 MB   | ########## | 100% \n\npip-21.2.2           | 1.8 MB    |            |   0% \npip-21.2.2           | 1.8 MB    | ########## | 100% \npip-21.2.2           | 1.8 MB    | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\nmkl_random-1.1.1     | 327 KB    |            |   0% \nmkl_random-1.1.1     | 327 KB    | ########## | 100% \n\nxz-5.2.5             | 339 KB    |            |   0% \nxz-5.2.5             | 339 KB    | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ####       |  41% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\nmkl-2020.2           | 138.3 MB  |            |   0% \nmkl-2020.2           | 138.3 MB  | 3          |   3% \nmkl-2020.2           | 138.3 MB  | 8          |   8% \nmkl-2020.2           | 138.3 MB  | #4         |  14% \nmkl-2020.2           | 138.3 MB  | ##         |  20% \nmkl-2020.2           | 138.3 MB  | ##7        |  28% \nmkl-2020.2           | 138.3 MB  | ###4       |  35% \nmkl-2020.2           | 138.3 MB  | ####1      |  42% \nmkl-2020.2           | 138.3 MB  | ####8      |  49% \nmkl-2020.2           | 138.3 MB  | #####5     |  56% \nmkl-2020.2           | 138.3 MB  | ######3    |  63% \nmkl-2020.2           | 138.3 MB  | #######    |  70% \nmkl-2020.2           | 138.3 MB  | #######7   |  78% \nmkl-2020.2           | 138.3 MB  | ########5  |  85% \nmkl-2020.2           | 138.3 MB  | #########2 |  92% \nmkl-2020.2           | 138.3 MB  | #########8 |  99% \nmkl-2020.2           | 138.3 MB  | ########## | 100% \n\nncurses-6.0          | 781 KB    |            |   0% \nncurses-6.0          | 781 KB    | ########## | 100% \nncurses-6.0          | 781 KB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.bx9wvsr_.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.42.0-py3-none-any.whl (2.0 kB)\nCollecting azureml-core~=1.42.0\n  Downloading azureml_core-1.42.0.post1-py3-none-any.whl (2.7 MB)\nCollecting azureml-dataset-runtime[fuse]~=1.42.0\n  Downloading azureml_dataset_runtime-1.42.0-py3-none-any.whl (2.2 kB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-inference-server-http~=0.4.1\n  Downloading azureml_inference_server_http-0.4.13-py3-none-any.whl (39 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\nCollecting azure-mgmt-containerregistry<10,>=8.2.0\n  Downloading azure_mgmt_containerregistry-9.1.0-py3-none-any.whl (1.1 MB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\nCollecting jmespath<=1.0.0\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting pytz\n  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\nCollecting azure-mgmt-resource<=21.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.0.0-py3-none-any.whl (2.3 MB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting python-dateutil<3.0.0,>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting knack~=0.9.0\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting urllib3<=1.26.9,>=1.23\n  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\nCollecting docker<6.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\nCollecting azure-core<=1.22.1\n  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\nCollecting packaging<22.0,>=20.0\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting msrest<0.7.0,>=0.5.1\n  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting importlib-metadata<5,>=0.23\n  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azure-core<=1.22.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.bx9wvsr_.requirements.txt (line 1)) (1.16.0)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.1-py3-none-any.whl (26 kB)\n  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\nCollecting azureml-dataprep<4.1.0a,>=4.0.0a\n  Downloading azureml_dataprep-4.0.4-py3-none-any.whl (43.4 MB)\nRequirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.bx9wvsr_.requirements.txt (line 1)) (1.19.2)\nCollecting pyarrow<4.0.0,>=0.17.0\n  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting jsonschema\n  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting azureml-dataprep-rslex~=2.6.0dev0\n  Downloading azureml_dataprep_rslex-2.6.3-cp36-cp36m-manylinux2010_x86_64.whl (15.5 MB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting itsdangerous<2.0,>=0.24\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\nCollecting click<8.0,>=5.1\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.4-py2.py3-none-any.whl (40 kB)\nCollecting flask==1.0.3\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\nCollecting inference-schema==1.3.0\n  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\nCollecting Werkzeug<2.0,>=0.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\nCollecting applicationinsights>=0.11.7\n  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting Jinja2<3.1,>=2.10.1\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->-r /azureml-environment-setup/condaenv.bx9wvsr_.requirements.txt (line 1)) (58.0.4)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\nCollecting typing-extensions>=3.6.4\n  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\nCollecting pygments\n  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\nCollecting tabulate\n  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from msrest<0.7.0,>=0.5.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.bx9wvsr_.requirements.txt (line 1)) (2021.5.30)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\nCollecting opencensus<1.0.0,>=0.8.0\n  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\nCollecting opencensus-context>=0.1.2\n  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\nCollecting protobuf<5.0.0dev,>=3.15.0\n  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.8-py3-none-any.whl (39 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting contextvars\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\nCollecting pyparsing!=3.0.5,>=2.0.2\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting immutables>=0.9\n  Downloading immutables-0.18-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\nCollecting pyrsistent>=0.14.0\n  Downloading pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=f51a0fbb87139cac6b233ae9f656ff7fef1f1d4f640a81682f40e99c7635ef23\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=7309af081dc7ea2da50abb8449819a295c4a5bf911e90d4affe11225d86c8a9e\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76170 sha256=b59f4b4a1da493c908bd03d88254cb632b36ad2d6874befcc14bfd03472feb67\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n  Building wheel for contextvars (setup.py): started\n  Building wheel for contextvars (setup.py): finished with status 'done'\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=1139463d22eb406db3219c20d080140c0e7a1b6785b22acef5acf3cddeaec257\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\nSuccessfully built json-logging-py fusepy wrapt contextvars\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, typing-extensions, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, immutables, cachetools, requests-oauthlib, python-dateutil, pyrsistent, msal-extensions, isodate, importlib-metadata, googleapis-common-protos, google-auth, distro, contextvars, azure-core, attrs, pyyaml, opencensus-context, msrest, MarkupSafe, jsonschema, google-api-core, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, Werkzeug, websocket-client, tabulate, pytz, PySocks, pyparsing, pyopenssl, pynacl, pygments, pyarrow, psutil, opencensus, msrestazure, jmespath, Jinja2, jeepney, itsdangerous, click, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.2 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 attrs-21.4.0 azure-common-1.1.28 azure-core-1.22.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-9.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-21.0.0 azure-mgmt-storage-20.0.0 azureml-core-1.42.0.post1 azureml-dataprep-4.0.4 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.6.3 azureml-dataset-runtime-1.42.0 azureml-defaults-1.42.0 azureml-inference-server-http-0.4.13 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.2 cachetools-4.2.4 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-36.0.2 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 flask-1.0.3 fusepy-3.0.1 google-api-core-2.8.2 google-auth-2.8.0 googleapis-common-protos-1.56.3 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 immutables-0.18 importlib-metadata-4.8.3 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-3.2.0 knack-0.9.0 msal-1.18.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.9.0 opencensus-context-0.1.2 opencensus-ext-azure-1.1.4 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.3 portalocker-2.4.0 protobuf-3.19.4 psutil-5.9.1 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.12.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyrsistent-0.18.0 python-dateutil-2.8.2 pytz-2022.1 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tabulate-0.8.10 typing-extensions-4.1.1 urllib3-1.26.9 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n\ndone\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.9.2\n  latest version: 4.13.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0m#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nWARNING: /root/.conda/pkgs does not exist\n\nRemoving intermediate container 53e61480d02b\n ---> ae56ad871ef0\nStep 9/21 : ENV PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin:$PATH\n ---> Running in d025c10bedf4\nRemoving intermediate container d025c10bedf4\n ---> 06c9e208b354\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> fc5666d4830b\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in 6d82ea5c47b4\nCopying environment context\nRemoving intermediate container 6d82ea5c47b4\n ---> b4cfda6bc7d9\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> 841f00505caa\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 253c89bb8ec1\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container 253c89bb8ec1\n ---> e3e8d7c21e67\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in af71e9e4dab0\nRemoving intermediate container af71e9e4dab0\n ---> f8df69184d17\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib:$LD_LIBRARY_PATH\n ---> Running in 2e5be372b557\nRemoving intermediate container 2e5be372b557\n ---> 7577c6109eeb\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_e220b045f6c3c3008b1a386af067185d CONDA_PREFIX=/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n ---> Running in 2968bd43c327\nRemoving intermediate container 2968bd43c327\n ---> 08d98a8466c1\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> 6ebcf17034b3\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in 92f66cf66696\nRemoving intermediate container 92f66cf66696\n ---> 19341fb6a2ba\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in b8a8b3eee594\nRemoving intermediate container b8a8b3eee594\n ---> 480351b2f414\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in be4a19ec3f88\nRemoving intermediate container be4a19ec3f88\n ---> af3aa8b8cf61\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 61be1b5f4cca\nRemoving intermediate container 61be1b5f4cca\n ---> 62d45ff5767a\n\nStreaming azureml-logs/55_azureml-execution-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt\n========================================================================================================================\n2022-06-22T21:02:00Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=51096 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-06-22T21:02:00Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/mounts/workspaceblobstore -- stdout/stderr: \n2022-06-22T21:02:00Z The vmsize standard_ds12_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-06-22T21:02:00Z Starting output-watcher...\n2022-06-22T21:02:00Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a\ne0b25ef51634: Pulling fs layer\n7b13e9939f7b: Pulling fs layer\n807ec43292c9: Pulling fs layer\n94f0b2b47a7c: Pulling fs layer\nbd6e09d7d402: Pulling fs layer\nb3757b0f5de5: Pulling fs layer\na106ee428b15: Pulling fs layer\nbc7243f99ccc: Pulling fs layer\ndbab89f33283: Pulling fs layer\n92da08bb365d: Pulling fs layer\nf4ba2934c358: Pulling fs layer\nc243525e6e96: Pulling fs layer\nd21180aff2a5: Pulling fs layer\n41090c6d20f3: Pulling fs layer\na2a9d72f89af: Pulling fs layer\n7e37e66c429d: Pulling fs layer\n74a3275e7926: Pulling fs layer\ne44d48a68272: Pulling fs layer\ndd4e7abe539c: Pulling fs layer\n94f0b2b47a7c: Waiting\nbd6e09d7d402: Waiting\nb3757b0f5de5: Waiting\na106ee428b15: Waiting\nbc7243f99ccc: Waiting\ndbab89f33283: Waiting\n92da08bb365d: Waiting\nf4ba2934c358: Waiting\n74a3275e7926: Waiting\nc243525e6e96: Waiting\ne44d48a68272: Waiting\ndd4e7abe539c: Waiting\nd21180aff2a5: Waiting\n41090c6d20f3: Waiting\na2a9d72f89af: Waiting\n7e37e66c429d: Waiting\n807ec43292c9: Verifying Checksum\n807ec43292c9: Download complete\ne0b25ef51634: Verifying Checksum\ne0b25ef51634: Download complete\n94f0b2b47a7c: Verifying Checksum\n94f0b2b47a7c: Download complete\nb3757b0f5de5: Verifying Checksum\nb3757b0f5de5: Download complete\na106ee428b15: Verifying Checksum\na106ee428b15: Download complete\n7b13e9939f7b: Verifying Checksum\n7b13e9939f7b: Download complete\nbd6e09d7d402: Verifying Checksum\nbd6e09d7d402: Download complete\nbc7243f99ccc: Verifying Checksum\nbc7243f99ccc: Download complete\ne0b25ef51634: Pull complete\ndbab89f33283: Verifying Checksum\ndbab89f33283: Download complete\nf4ba2934c358: Download complete\n92da08bb365d: Verifying Checksum\n92da08bb365d: Download complete\nd21180aff2a5: Verifying Checksum\nd21180aff2a5: Download complete\n41090c6d20f3: Verifying Checksum\n41090c6d20f3: Download complete\na2a9d72f89af: Download complete\n7e37e66c429d: Verifying Checksum\n7e37e66c429d: Download complete\n74a3275e7926: Verifying Checksum\n74a3275e7926: Download complete\ne44d48a68272: Verifying Checksum\ne44d48a68272: Download complete\ndd4e7abe539c: Verifying Checksum\ndd4e7abe539c: Download complete\nc243525e6e96: Verifying Checksum\nc243525e6e96: Download complete\n7b13e9939f7b: Pull complete\n807ec43292c9: Pull complete\n94f0b2b47a7c: Pull complete\nbd6e09d7d402: Pull complete\nb3757b0f5de5: Pull complete\na106ee428b15: Pull complete\nbc7243f99ccc: Pull complete\ndbab89f33283: Pull complete\n92da08bb365d: Pull complete\nf4ba2934c358: Pull complete\nc243525e6e96: Pull complete\nd21180aff2a5: Pull complete\n41090c6d20f3: Pull complete\na2a9d72f89af: Pull complete\n7e37e66c429d: Pull complete\n74a3275e7926: Pull complete\ne44d48a68272: Pull complete\ndd4e7abe539c: Pull complete\nDigest: sha256:827f6aea3b77adba06a985afe197787070432a1aaee0e5b7ae3fb65a90c602e3\nStatus: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\nviennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\n2022-06-22T21:02:15Z The vmsize standard_ds12_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-06-22T21:02:16Z Check if container 227bf318-7aad-4e00-8bc3-16793e06a13c_DataSidecar already exist exited with 0, \n\n4ea971c81418d1412beb1ca1074ecc714be0ec1cf78cf5b2df79c9a7c5b5bcd5\n2022-06-22T21:02:16Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-06-22T21:02:16Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-0c697a1b80c9dfb46ae54dbe38e1b8a1-578a9b2e25d20ecd-01 -sshRequired=false] \n2022/06/22 21:02:16 Didn't get JobInfoJson from env, now read from file\n2022/06/22 21:02:16 Suceeded read JobInfoJson from file\n2022/06/22 21:02:16 Starting App Insight Logger for task:  containerSetup\n2022/06/22 21:02:16 Version: 3.0.01992.0001 Branch: .SourceBranch Commit: f1c8f01\n2022/06/22 21:02:16 Entered ContainerSetupTask - Preparing infiniband\n2022/06/22 21:02:16 Starting infiniband setup\n2022/06/22 21:02:16 Python Version found is Python 3.7.9\n\n2022/06/22 21:02:16 Returning Python Version as 3.7\n2022-06-22T21:02:16Z VMSize: standard_ds12_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/06/22 21:02:16 VMSize: standard_ds12_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/06/22 21:02:16 VMSize: standard_ds12_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/06/22 21:02:16 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022-06-22T21:02:16Z Not setting up Infiniband in Container\n2022/06/22 21:02:16 Not setting up Infiniband in Container\n2022/06/22 21:02:16 Not setting up Infiniband in Container\n2022/06/22 21:02:16 Python Version found is Python 3.7.9\n\n2022/06/22 21:02:16 Returning Python Version as 3.7\n2022/06/22 21:02:16 sshd inside container not required for job, skipping setup.\n2022/06/22 21:02:17 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/06/22 21:02:17 App Insight Client has already been closed\n2022/06/22 21:02:17 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-06-22T21:02:17Z Starting docker container succeeded.\n2022-06-22T21:02:17Z The vmsize standard_ds12_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n\nStreaming azureml-logs/65_job_prep-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt\n===============================================================================================================\n[2022-06-22T21:02:19.212469] Entering job preparation.\n[2022-06-22T21:02:19.712989] Starting job preparation.\n[2022-06-22T21:02:19.713024] Extracting the control code.\n[2022-06-22T21:02:19.713286] Starting extract_project.\n[2022-06-22T21:02:19.713321] Starting to extract zip file.\n[2022-06-22T21:02:19.728231] Finished extracting zip file.\n[2022-06-22T21:02:19.731232] Using urllib.request Python 3.0 or later\n[2022-06-22T21:02:19.731271] Start fetching snapshots.\n[2022-06-22T21:02:19.731301] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 51\n[2022-06-22T21:02:20.043640] Finished fetching snapshot.\n[2022-06-22T21:02:20.043675] Start fetching snapshot.\n[2022-06-22T21:02:25.831245] Finished fetching snapshot.\n[2022-06-22T21:02:25.831284] Finished fetching snapshots.\n[2022-06-22T21:02:25.831291] Finished extract_project.\n[2022-06-22T21:02:25.831348] Finished fetching and extracting the control code.\n[2022-06-22T21:02:25.837886] Start run_history_prep.\n[2022-06-22T21:02:25.845566] Job preparation is complete.\n[2022-06-22T21:02:25.845699] Entering Data Context Managers in Sidecar\n[2022-06-22T21:02:25.851656] Running Sidecar prep cmd...\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-06-22T21:02:26.241517] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/azureml/227bf318-7aad-4e00-8bc3-16793e06a13c\n[2022-06-22T21:02:26.242153] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-06-22T21:02:26.326] Enter __enter__ of DatasetContextManager\n[2022-06-22T21:02:26.326] SDK version: azureml-core==1.41.0.post1 azureml-dataprep==3.1.2. Session id: a2598eed-cd75-4ec3-8e29-c5e0a1fb84da. Run id: 227bf318-7aad-4e00-8bc3-16793e06a13c.\n[2022-06-22T21:02:26.326] Processing 'diabetes_batch'.\n[2022-06-22T21:02:26.326] Mode: 'mount'.\n[2022-06-22T21:02:26.326] Path on compute is specified: 'False'.\n[2022-06-22T21:02:26.327] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: diabetes_batch\n[2022-06-22T21:02:28.786] Processing dataset FileDataset\n{\n  \"source\": [\n    \"('workspaceblobstore', 'batch-data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"585542bf-b252-4b2b-8708-2a128fdddc74\",\n    \"name\": \"batch-data\",\n    \"version\": 1,\n    \"description\": \"batch data\",\n    \"workspace\": \"Workspace.create(name='ml-lab-s534vtqj735ae', subscription_id='6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef', resource_group='cal-983-32')\"\n  }\n}\n[2022-06-22T21:02:29.652] Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74 as folder.\n[2022-06-22T21:02:29.652] Processing 'inferences'.\n[2022-06-22T21:02:29.652] Mode: 'mount'.\n[2022-06-22T21:02:29.652] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore'.\n[2022-06-22T21:02:29.771] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore\n[2022-06-22T21:02:29.771] Output is not a single file\n[2022-06-22T21:02:29.771] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore as folder\n[2022-06-22T21:02:30.291] Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74.\n[2022-06-22T21:02:31.292] Mounted diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74.\n[2022-06-22T21:02:31.292] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore.\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-06-22T21:02:34.353] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore.\n[2022-06-22T21:02:34.406] Exit __enter__ of DatasetContextManager\nuri entered in sidecar: None\nSet Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74\nSet OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore\n[2022-06-22T21:02:34.407058] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-06-22T21:02:35.106848] Ran Sidecar prep cmd.\n[2022-06-22T21:02:35.106940] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/06/22 21:03:05 Didn't get JobInfoJson from env, now read from file\n2022/06/22 21:03:05 Suceeded read JobInfoJson from file\n2022/06/22 21:03:05 Starting App Insight Logger for task:  runTaskLet\n2022/06/22 21:03:05 Version: 3.0.01992.0001 Branch: .SourceBranch Commit: f1c8f01\n2022/06/22 21:03:05 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2022/06/22 21:03:05 Send process info logs to master server succeeded\n2022/06/22 21:03:05 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/06/22 21:03:05 Send process info logs to master server succeeded\n[2022-06-22T21:03:05.639828] Entering context manager injector.\n[2022-06-22T21:03:06.186723] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.42.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'])\nScript type = None\n[2022-06-22T21:03:06.190697] Entering Run History Context Manager.\n[2022-06-22T21:03:06.924171] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/azureml/227bf318-7aad-4e00-8bc3-16793e06a13c\n[2022-06-22T21:03:06.924439] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.42.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'diabetes_batch']\n[2022-06-22T21:03:06.924465] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.42.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore', '--input_fds_0', 'diabetes_batch']\n\n2022/06/22 21:03:10 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\n\n[2022-06-22T21:04:06.829749] The experiment completed successfully. Finalizing run...\nCleaning up all outstanding Run operations, waiting 900.0 seconds\n3 items cleaning up...\nCleanup took 0.16922235488891602 seconds\n[2022-06-22T21:04:07.122034] Finished context manager injector.\n2022/06/22 21:04:08 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/06/22 21:04:08 Send process info logs to master server succeeded\n2022/06/22 21:04:08 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2022/06/22 21:04:08 Process Exiting with Code:  0\n2022/06/22 21:04:08 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n\nStreaming azureml-logs/75_job_post-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt\n===============================================================================================================\n[2022-06-22T21:04:10.279013] Entering job release\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-06-22T21:04:11.054591] job release stage : copy_batchai_cached_logs starting...\n[2022-06-22T21:04:11.054627] job release stage : copy_batchai_cached_logs completed...\n[2022-06-22T21:04:11.054673] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-06-22T21:04:11.055102] Running Sidecar release cmd...\n[2022-06-22T21:04:11.063304] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/azureml/227bf318-7aad-4e00-8bc3-16793e06a13c\n[2022-06-22T21:04:11.080] Enter __exit__ of DatasetContextManager\n[2022-06-22T21:04:11.081] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74.\n[2022-06-22T21:04:12.081] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/diabetes_batch_585542bf-b252-4b2b-8708-2a128fdddc74.\n[2022-06-22T21:04:12.081] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore.\n[2022-06-22T21:04:12.096] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-lab-s534vtqj735ae/a49f8d6092e540e1ac37ce8767df8814/227bf318-7aad-4e00-8bc3-16793e06a13c/wd/inferences_workspaceblobstore.\n[2022-06-22T21:04:12.096] Exit __exit__ of DatasetContextManager\n[2022-06-22T21:04:12.096605] Removing absolute paths from host...\n[2022-06-22T21:04:12.096962] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-06-22T21:04:12.295141] Ran Sidecar release cmd.\n\nStepRun(batch-score-diabetes) Execution Summary\n================================================\nStepRun( batch-score-diabetes ) Status: Finished\n{'runId': '227bf318-7aad-4e00-8bc3-16793e06a13c', 'target': 'automl-compute', 'status': 'Completed', 'startTimeUtc': '2022-06-22T21:01:55.675285Z', 'endTimeUtc': '2022-06-22T21:04:32.974175Z', 'services': {}, 'properties': {'ContentSnapshotId': '65cdcade-2b94-4755-90d4-0d090dd94d69', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'f0f258cc-51a1-41cd-9397-8d8115ac90a9', 'azureml.moduleName': 'batch-score-diabetes', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '5dd9d453', 'azureml.pipelinerunid': 'a1f73378-9987-44a9-8a9e-1411755519f4', 'azureml.pipeline': 'a1f73378-9987-44a9-8a9e-1411755519f4', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '585542bf-b252-4b2b-8708-2a128fdddc74'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount'}}], 'outputDatasets': [{'identifier': {'savedId': '8a018a9c-ac4b-4a5c-8f93-b41842ad75e2'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/227bf318-7aad-4e00-8bc3-16793e06a13c/inferences/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"8a018a9c-ac4b-4a5c-8f93-b41842ad75e2\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ml-lab-s534vtqj735ae', subscription_id='6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef', resource_group='cal-983-32')\"\n  }\n}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.42.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'automl-compute', 'dataReferences': {}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': '585542bf-b252-4b2b-8708-2a128fdddc74', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': 'a1f73378-9987-44a9-8a9e-1411755519f4', 'azureml.pipelineRun.moduleNodeId': '5dd9d453', 'azureml.pipelineRun.outputPortName': 'inferences'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2022-06-22T20:45:25Z_b5f7ee50', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'batch_environment', 'dependencies': ['python=3.6.2', 'scikit-learn', 'pip', {'pip': ['azureml-defaults']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220504.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=y6rJeBwk%2FZyAKM%2BtaIg3FiuBu3Wj0AAH9UVGYztgVmg%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/55_azureml-execution-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt?sv=2019-07-07&sr=b&sig=xejhWzrFHJqSrmTLmLGIZjtA3mRb6IKlM50iWpG3rVA%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/55_azureml-execution-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt?sv=2019-07-07&sr=b&sig=tRoxAisX3fZsM24vEA0hby5CObbCzAo6Gpei4RRH770%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/65_job_prep-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt?sv=2019-07-07&sr=b&sig=hOuooC1zqzAdthTd7rb5%2FwWwS9X001Xs2djDhzaU6Ng%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/65_job_prep-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt?sv=2019-07-07&sr=b&sig=7Iv6EbJlLb66OByarTlOi3VXsv0ynep%2FJOb8tG9Ud2w%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=ZXMlktqfo0PONZbc1zNvfMan2omrIfxb662vO4ZhZy8%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/75_job_post-tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p.txt?sv=2019-07-07&sr=b&sig=nUpXE2oU2caQPZXNloDcyEY86YKPIHoonIryGm5iqcg%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/75_job_post-tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p.txt?sv=2019-07-07&sr=b&sig=JaZ1kAazmvaG6oAn4txDnBvAQFJUvUCJgojBUNy4io0%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/process_info.json': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=qX0ebihnXDj1Zh2L5kO2jEJZAdsdSYXxSeg3FG%2B0vhU%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'azureml-logs/process_status.json': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=erILo1XspyaCR4piUAS44QGg3hk%2B19G7AxvVs%2F%2FDQgg%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/103_azureml.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/103_azureml.log?sv=2019-07-07&sr=b&sig=%2FussBPAYXmzugVkmgHJGiyPKfW3NG%2Fmmuz5oHAXoUt0%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/89_azureml.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/89_azureml.log?sv=2019-07-07&sr=b&sig=HOqq7A62DpHhdFDYrq%2FtGjPUH1Bpa6aXbI5pBmjj%2F28%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Ws93g5gq2sO%2BlfVv1LKnumWwjTIyE6k%2B%2BtzAtg%2BTud8%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=dXHNbO1SWh9C3vbyD%2FwFqaF3%2FwkQtuaQtRBwXsDFMqU%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Xji7unAjjH1F4qawWIxd%2BVZHKiewwiEDQMSVBfBuwok%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=QfHWeHCTMqb5wjaQt3E9RFRxwYaJWMa%2BtH%2By4n%2Bikww%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=0EJ8gZ70KxTc0i1d7B6MopgE%2B3zkOkq%2FRppzkoweJBc%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/all.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/all.log?sv=2019-07-07&sr=b&sig=t4ar5gnN11SUdAkfx2WWLP2wqdz565%2F0cElkAsCJbQ0%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/task.enter_contexts.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=rpKQTtgobN13ylbYwSBkJnm9jmnKi7VVFZWFaNNSeD4%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/task.exit_contexts.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_8084fb9cd45b067763285ee6db34b167940d11d26bbd6faf1f42203d3d20b407_p/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=eBp3EfQtJctb%2BcdVUJ3HhOM60fagCMFoeXme1V4TsDY%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/all.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/all.log?sv=2019-07-07&sr=b&sig=VNbyfIjg8ffOO3JtkuW4J97PzNfz6wS%2Fa%2FKiPky6DgU%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/task.enter_contexts.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=ILZ1UY357M5OQf0Kts5FlJ4TETbYjKmpcMOUSxd5uUs%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/task.exit_contexts.log': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/sidecar/tvmps_f10bc548de686215f751fe2c7653e007242e43c684718304ee85a87b39c88a6b_p/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=Lw%2F4rCZrat6k86fMJkGRnysrGHRuWyW3QNCbxAZng6o%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=QpmQCQn2BzHQdAa6w6xG6ITpkCmUdiLmgnnIfBNToqE%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.227bf318-7aad-4e00-8bc3-16793e06a13c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=LZYUZzxQjYKRunMwMG%2FhQ4pq9rAN6pXOuVfIaOAUBxE%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A15Z&se=2022-06-23T05%3A04%3A15Z&sp=r'}, 'submittedBy': 'student-983-1294682'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'a1f73378-9987-44a9-8a9e-1411755519f4', 'status': 'Completed', 'startTimeUtc': '2022-06-22T20:44:33.8256Z', 'endTimeUtc': '2022-06-22T21:04:34.734307Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.a1f73378-9987-44a9-8a9e-1411755519f4/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=QLz3AV0AgC%2FUShdonbjhuYZTe3YYhIki3gPX7ZmRyF0%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A36Z&se=2022-06-23T05%3A04%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.a1f73378-9987-44a9-8a9e-1411755519f4/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=hunZuhgYHPUtst2qzvsbS7t9pwyKm4sl%2BweDTpKthEQ%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A36Z&se=2022-06-23T05%3A04%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.a1f73378-9987-44a9-8a9e-1411755519f4/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=1Z4lzxbBIhKIxafbiPcaaK4ZpgiwiO%2FFbmUrGxJY%2FIs%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T20%3A54%3A36Z&se=2022-06-23T05%3A04%3A36Z&sp=r'}, 'submittedBy': 'student-983-1294682'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655931877936
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           1\n1   12.csv           0\n2   13.csv           0\n3   14.csv           1\n4   15.csv           1\n5   16.csv           0\n6   17.csv           0\n7   18.csv           1\n8   19.csv           0\n9    2.csv           1\n10  20.csv           1\n11  21.csv           1\n12  22.csv           0\n13  23.csv           0\n14  24.csv           1\n15  25.csv           0\n16  26.csv           0\n17  27.csv           0\n18  28.csv           1\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655931941753
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the Pipeline and use its REST Interface\r\n",
        "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-batch-pipeline,\nId: d5a70902-842e-4820-99d3-33bfacc7620f,\nStatus: Active,\nEndpoint: https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourceGroups/cal-983-32/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-s534vtqj735ae/PipelineRuns/PipelineSubmit/d5a70902-842e-4820-99d3-33bfacc7620f)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/d5a70902-842e-4820-99d3-33bfacc7620f?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-983-32/workspaces/ml-lab-s534vtqj735ae\" target=\"_blank\" rel=\"noopener\">d5a70902-842e-4820-99d3-33bfacc7620f</a></td><td>Active</td><td><a href=\"https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourceGroups/cal-983-32/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-s534vtqj735ae/PipelineRuns/PipelineSubmit/d5a70902-842e-4820-99d3-33bfacc7620f\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655932099429
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\r\n",
        "\r\n",
        "**Note**: A real application would require a service principal with which to be authenticated."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "print('Authentication header ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655932212262
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, \r\n",
        "                         headers=auth_header, \r\n",
        "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'fd911662-59cc-49e5-8d3d-f7ebb5c13dab'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655932240502
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have the run ID, we can use the **RunDetails** widget to view the experiment as it runs:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\r\n",
        "\r\n",
        "# Block until the run completes\r\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: fd911662-59cc-49e5-8d3d-f7ebb5c13dab\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/fd911662-59cc-49e5-8d3d-f7ebb5c13dab?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-983-32/workspaces/ml-lab-s534vtqj735ae&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'fd911662-59cc-49e5-8d3d-f7ebb5c13dab', 'status': 'Completed', 'startTimeUtc': '2022-06-22T21:10:40.811106Z', 'endTimeUtc': '2022-06-22T21:10:42.899747Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineid': 'd5a70902-842e-4820-99d3-33bfacc7620f', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.fd911662-59cc-49e5-8d3d-f7ebb5c13dab/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=lZX77bybD6nEWPs8vhphRxOVX8rOX9W7av517V5iWls%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T21%3A02%3A12Z&se=2022-06-23T05%3A12%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.fd911662-59cc-49e5-8d3d-f7ebb5c13dab/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=lEwMKzeMYgfBM5bXM76XEGoLcF8rXinOBtwlWYViSPU%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T21%3A02%3A12Z&se=2022-06-23T05%3A12%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabs534vtqj735ae.blob.core.windows.net/azureml/ExperimentRun/dcid.fd911662-59cc-49e5-8d3d-f7ebb5c13dab/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=tbv%2BDlB54czV2eS4YNqEt4ait6h6MS6zf7c1Gz%2BdgjU%3D&skoid=57630c9e-eeda-43b1-87a4-60e37e102d36&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T19%3A34%3A37Z&ske=2022-06-24T03%3A44%3A37Z&sks=b&skv=2019-07-07&st=2022-06-22T21%3A02%3A12Z&se=2022-06-23T05%3A12%3A12Z&sp=r'}, 'submittedBy': 'student-983-1294682'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655932334493
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait for the pipeline run to complete, and then run the following cell to see the results.\r\n",
        "\r\n",
        "As before, the results are in the output of the first pipeline step:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           1\n1   12.csv           0\n2   13.csv           0\n3   14.csv           1\n4   15.csv           1\n5   16.csv           0\n6   17.csv           0\n7   18.csv           1\n8   19.csv           0\n9    2.csv           1\n10  20.csv           1\n11  21.csv           1\n12  22.csv           0\n13  23.csv           0\n14  24.csv           1\n15  25.csv           0\n16  26.csv           0\n17  27.csv           0\n18  28.csv           1\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655932451987
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have a pipeline that can be used to batch process daily patient data.\r\n",
        "\r\n",
        "More Information: For more details about using pipelines for batch inferencing, see the [How to Run Batch Predictions](https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions) in the Azure Machine Learning documentation."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}