{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.42.0 to work with ml-lab-eah62qb7osjim\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655905427084
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "default_ds=ws.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastores, indicating which is the default\r\n",
        "for ds_name in ws.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspaceartifactstore - Default = False\nworkspacefilestore - Default = False\nworkspaceworkingdirectory - Default = False\nworkspaceblobstore - Default = True\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655905435468
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tab_data_set=Dataset.get_by_name(ws,name=\"diabetes dataset\")\r\n",
        "tab_data_set.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n0    1354778            0            171                      80   \n1    1147438            8             92                      93   \n2    1640031            7            115                      47   \n3    1883350            9            103                      78   \n4    1424119            1             85                      59   \n\n   TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0                34            23  43.509726          1.213191   21         0  \n1                47            36  21.240576          0.158365   23         0  \n2                52            35  41.511523          0.079019   23         0  \n3                25           304  29.582192          1.282870   43         1  \n4                27            35  42.604536          0.549542   22         0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655905454314
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create scripts for pipeline steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = 'diabetes_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_pipeline\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655905465398
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create the first script, which will read data from the diabetes dataset and apply some simple pre-processing to remove any rows with missing data and normalize the numeric features so they're on a similar scale.\r\n",
        "\r\n",
        "The script includes a argument named **--prepped-data**, which references the folder where the resulting data should be saved."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "from azureml.core import Run\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\r\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\r\n",
        "\r\n",
        "args=parser.parse_args()\r\n",
        "save_folder = args.prepped_data\r\n",
        "\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run= Run.get_context()\r\n",
        "\r\n",
        "# Load the data(passed as an input data)\r\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\r\n",
        "\r\n",
        "# log raw row count\r\n",
        "row_count =(len(diabetes))\r\n",
        "run.log('raw_rows',row_count)\r\n",
        "\r\n",
        "# remove nulls\r\n",
        "diabetes = diabetes.dropna()\r\n",
        "\r\n",
        "# Normalize the numeric columns\r\n",
        "scaler = MinMaxScaler()\r\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\r\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\r\n",
        "\r\n",
        "# Log processed rows\r\n",
        "row_count = (len(diabetes))\r\n",
        "run.log('processed_rows', row_count)\r\n",
        "\r\n",
        "# Save the prepped data\r\n",
        "print(\"Saving Data...\")\r\n",
        "os.makedirs(save_folder, exist_ok=True)\r\n",
        "save_path = os.path.join(save_folder,'data.csv')\r\n",
        "diabetes.to_csv(save_path, index=False, header=True)\r\n",
        "\r\n",
        "# End the run\r\n",
        "run.complete()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes_pipeline/prep_diabetes.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can create the script for the second step, which will train a model. The script includes a argument named **--training-data**, which references the location where the prepared data was saved by the previous step."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\r\n",
        "# Import libraries\r\n",
        "from azureml.core import Run, Model\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\r\n",
        "#parser.add_argument(\"--model-dir\", type=str, dest='model_dir', help='model file')\r\n",
        "args = parser.parse_args()\r\n",
        "training_data = args.training_data\r\n",
        "#outputs=args.model_dir\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the prepared data file in the training folder\r\n",
        "print(\"Loading Data...\")\r\n",
        "file_path = os.path.join(training_data,'data.csv')\r\n",
        "diabetes = pd.read_csv(file_path)\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "# Train adecision tree model\r\n",
        "print('Training a decision tree model...')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# plot ROC curve\r\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\r\n",
        "fig = plt.figure(figsize=(6, 4))\r\n",
        "# Plot the diagonal 50% line\r\n",
        "plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "# Plot the FPR and TPR achieved by our model\r\n",
        "plt.plot(fpr, tpr)\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title('ROC Curve')\r\n",
        "run.log_image(name = \"ROC\", plot = fig)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Save the trained model in the outputs folder\r\n",
        "print(\"Saving model...\")\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "\r\n",
        "# Register the model\r\n",
        "print('Registering model...')\r\n",
        "\r\n",
        "Model.register(workspace=run.experiment.workspace,\r\n",
        "               model_path = model_file,\r\n",
        "               model_name = 'diabetes_model',\r\n",
        "               tags={'Training context':'Pipeline'},\r\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\r\n",
        "\r\n",
        "'''\r\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\r\n",
        "                   tags={'Training context':'Pipeline'},\r\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\r\n",
        "\r\n",
        "'''\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes_pipeline/train_diabetes.py\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy Script\r\n",
        "\r\n",
        "The deploy step takes the newly trained model and deploys it as a web service endpoint:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Script file**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/score_diabetes.py\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['not-diabetic', 'diabetic']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes_pipeline/score_diabetes.py\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/deploy.py\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "from azureml.exceptions import WebserviceException\r\n",
        "import argparse\r\n",
        "\r\n",
        "#model=Model.get_model_path('diabetes_model')\r\n",
        "\r\n",
        "# Define arguments\r\n",
        "parser = argparse.ArgumentParser(description='Deploy arg parser')\r\n",
        "#parser.add_argument('--test_dir', type=str, help='Directory where testing data is stored')\r\n",
        "#parser.add_argument('--model_dir', type=str, help='File storing the evaluation accuracy')\r\n",
        "parser.add_argument(\"--model-dir\", type=str, dest='model_dir', help='model file')\r\n",
        "#parser.add_argument('--accuracy_dir', type=str, help='File storing the evaluation accuracy')\r\n",
        "\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "# Get run context\r\n",
        "run = Run.get_context()\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "#accuracy_dir = args.accuracy_dir\r\n",
        "model_dir = args.model_dir\r\n",
        "\r\n",
        "'''\r\n",
        "if not os.path.exists(model_dir):\r\n",
        "    os.makedirs(model_dir)\r\n",
        "'''\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment(name='service-env')\r\n",
        "\r\n",
        "# Register environment to re-use later\r\n",
        "service_env.register(workspace = workspace)\r\n",
        "\r\n",
        "# Service name\r\n",
        "service_name = \"diabetes-service\"\r\n",
        "\r\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\r\n",
        "for package in python_packages:\r\n",
        "    service_env.python.conda_dependencies.add_pip_package(package)\r\n",
        "new_model=True\r\n",
        "\r\n",
        "if new_model:\r\n",
        "    inference_config = InferenceConfig(source_directory=experiment_folder,\r\n",
        "                                    entry_script=\"score_diabetes.py\",\r\n",
        "                                    environment=service_env)\r\n",
        "\r\n",
        "    # Configure the web service container\r\n",
        "    deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "    try:\r\n",
        "        service=Webservice(workspace,name=service_name)\r\n",
        "        if service:\r\n",
        "            service.delete()\r\n",
        "    except WebserviceException as e:\r\n",
        "        print()\r\n",
        "    # Deploy the model as a service\r\n",
        "    print('Deploying model...')\r\n",
        "\r\n",
        "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "    service.wait_for_deployment(True)\r\n",
        "else:\r\n",
        "    service = Webservice(workspace, name=service_name)\r\n",
        "\r\n",
        "print(service.state)\r\n",
        "'''\r\n",
        "# Output scoring url to file\r\n",
        "print(service.scoring_uri)\r\n",
        "with open(model_dir + '/scoring_uri.txt', 'w+') as f:\r\n",
        "    f.write(service.scoring_uri)\r\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes_pipeline/deploy.py\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a compute environment for the pipeline steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"automl-compute\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655907209359
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compute will require a Python environment with the necessary package dependencies installed."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\r\n",
        "name: experiment_env\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have a Conda configuration file, you can create an environment and use it in the run configuration for the pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\r\n",
        "\r\n",
        "# Register the environment\r\n",
        "experiment_env.register(workspace=ws)\r\n",
        "registered_env=Environment.get(ws,'experiment_env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipemine\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above\r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655907221546
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and run a pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        "from azureml.pipeline.core import PipelineData\r\n",
        "from azureml.data.data_reference import DataReference\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "# Get datastore reference\r\n",
        "datastore_reference = DataReference(datastore, mode='mount')\r\n",
        "\r\n",
        "\r\n",
        "output_dir = PipelineData(\r\n",
        "    name='output_dir', \r\n",
        "    pipeline_output_name='outputdir',\r\n",
        "    datastore=datastore_reference.datastore,\r\n",
        "    output_mode='mount',\r\n",
        "    is_directory=True)\r\n",
        "\r\n",
        "\r\n",
        "model_dir = PipelineData(\r\n",
        "    name='model_dir', \r\n",
        "    pipeline_output_name='modeldir',\r\n",
        "    datastore=datastore_reference.datastore,\r\n",
        "    output_mode='mount',\r\n",
        "    is_directory=True)\r\n",
        "'''\r\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655907229666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "#from azureml.core.model import Model\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step =PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"prep_diabetes.py\",\r\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"train_diabetes.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "\r\n",
        "#model_dir=Model.get_model_path('diabetes_model')\r\n",
        "model_dir = ws.models['diabetes_model']\r\n",
        "'''\r\n",
        "# Step 3, run the training script\r\n",
        "deploy_step = PythonScriptStep(name = \"Deploy Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"deploy.py\",\r\n",
        "                                arguments=[\"--model_dir\",model_dir],\r\n",
        "                                inputs=[model_dir],\r\n",
        "                                #outputs=[output_dir],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "'''\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655909276805
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prep_step, train_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [ddf4899a][f4dc21bb-d8e7-4917-a389-d4ddc4e9a224], (This step will run and generate new outputs)\nCreated step Train and Register Model [876dc45d][13a39436-b182-403d-bd6c-62c39c265306], (This step will run and generate new outputs)\nSubmitted PipelineRun c3aad46f-e2c0-49f5-9854-e2b3ff63c77d\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/c3aad46f-e2c0-49f5-9854-e2b3ff63c77d?wsid=/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourcegroups/cal-3727-34/workspaces/ml-lab-eah62qb7osjim&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca187a0e14c4ec2b5b526a6af3d893f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/c3aad46f-e2c0-49f5-9854-e2b3ff63c77d?wsid=/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourcegroups/cal-3727-34/workspaces/ml-lab-eah62qb7osjim&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\", \"run_id\": \"c3aad46f-e2c0-49f5-9854-e2b3ff63c77d\", \"run_properties\": {\"run_id\": \"c3aad46f-e2c0-49f5-9854-e2b3ff63c77d\", \"created_utc\": \"2022-06-22T14:48:16.609887Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-06-22T14:52:29.454931Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=pfISeJoE6YcLr9iK7vHKriWS%2FrQPX6GnAIs1NsyAExQ%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T15%3A15%3A24Z&se=2022-06-22T23%3A25%3A24Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=KdIAHsOGxoEjKp6%2FNN9IWghiRPuftdeqeo7AFbQX1Mo%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T15%3A15%3A24Z&se=2022-06-22T23%3A25%3A24Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ASjHB6JZn8ftOg15Xw1AYAJuZK7PGJ73PnfAIf2FSqo%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T15%3A15%3A24Z&se=2022-06-22T23%3A25%3A24Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:04:12\", \"run_number\": \"1655909296\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"3a5f6731-6997-4003-ae5f-d5e897f49918\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-06-22T14:51:10.199222Z\", \"created_time\": \"2022-06-22T14:48:18.406397Z\", \"end_time\": \"2022-06-22T14:52:08.18451Z\", \"duration\": \"0:03:49\", \"run_number\": 1655909298, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-22T14:48:18.406397Z\", \"is_reused\": \"\"}, {\"run_id\": \"a9744dfa-dc2c-4ee2-ab2f-297644385a95\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-06-22T14:52:14.924899Z\", \"created_time\": \"2022-06-22T14:52:09.657559Z\", \"end_time\": \"2022-06-22T14:52:28.608362Z\", \"duration\": \"0:00:18\", \"run_number\": 1655909529, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-22T14:52:09.657559Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-06-22 14:48:18Z] Submitting 1 runs, first five are: ddf4899a:3a5f6731-6997-4003-ae5f-d5e897f49918\\n[2022-06-22 14:52:09Z] Completing processing run id 3a5f6731-6997-4003-ae5f-d5e897f49918.\\n[2022-06-22 14:52:09Z] Submitting 1 runs, first five are: 876dc45d:a9744dfa-dc2c-4ee2-ab2f-297644385a95\\n[2022-06-22 14:52:29Z] Completing processing run id a9744dfa-dc2c-4ee2-ab2f-297644385a95.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"4317b852\": {\"node_id\": \"4317b852\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"ddf4899a\": {\"node_id\": \"ddf4899a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"3a5f6731-6997-4003-ae5f-d5e897f49918\"}, \"876dc45d\": {\"node_id\": \"876dc45d\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"a9744dfa-dc2c-4ee2-ab2f-297644385a95\"}}, \"edges\": [{\"source_node_id\": \"4317b852\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"ddf4899a\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"ddf4899a\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_0fb7f802\", \"dst_node_id\": \"876dc45d\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"3a5f6731-6997-4003-ae5f-d5e897f49918\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-06-22T14:51:10.199222Z\", \"created_time\": \"2022-06-22T14:48:18.406397Z\", \"end_time\": \"2022-06-22T14:52:08.18451Z\", \"duration\": \"0:03:49\", \"run_number\": 1655909298, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-22T14:48:18.406397Z\", \"is_reused\": \"\"}, {\"run_id\": \"a9744dfa-dc2c-4ee2-ab2f-297644385a95\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-06-22T14:52:14.924899Z\", \"created_time\": \"2022-06-22T14:52:09.657559Z\", \"end_time\": \"2022-06-22T14:52:28.608362Z\", \"duration\": \"0:00:18\", \"run_number\": 1655909529, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-22T14:52:09.657559Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.42.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: c3aad46f-e2c0-49f5-9854-e2b3ff63c77d\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/c3aad46f-e2c0-49f5-9854-e2b3ff63c77d?wsid=/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourcegroups/cal-3727-34/workspaces/ml-lab-eah62qb7osjim&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 3a5f6731-6997-4003-ae5f-d5e897f49918\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/3a5f6731-6997-4003-ae5f-d5e897f49918?wsid=/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourcegroups/cal-3727-34/workspaces/ml-lab-eah62qb7osjim&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nStepRun( Prepare Data ) Status: Running\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': '3a5f6731-6997-4003-ae5f-d5e897f49918', 'target': 'automl-compute', 'status': 'Completed', 'startTimeUtc': '2022-06-22T14:51:10.199222Z', 'endTimeUtc': '2022-06-22T14:52:08.18451Z', 'services': {}, 'properties': {'ContentSnapshotId': '1f982bf1-306c-4bc8-9cdd-824efd225b3c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'f4dc21bb-d8e7-4917-a389-d4ddc4e9a224', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'ddf4899a', 'azureml.pipelinerunid': 'c3aad46f-e2c0-49f5-9854-e2b3ff63c77d', 'azureml.pipeline': 'c3aad46f-e2c0-49f5-9854-e2b3ff63c77d', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '0fe311a8-03b6-49c7-89d5-35479cd1d1e3'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': 'a52001c8-1208-4622-8811-4b9d49b41197'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/3a5f6731-6997-4003-ae5f-d5e897f49918/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"a52001c8-1208-4622-8811-4b9d49b41197\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ml-lab-eah62qb7osjim', subscription_id='1180d7d2-bb0a-4c4a-8011-1a73b31a7318', resource_group='cal-3727-34')\"\n  }\n}}], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'automl-compute', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '0fe311a8-03b6-49c7-89d5-35479cd1d1e3', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': 'c3aad46f-e2c0-49f5-9854-e2b3ff63c77d', 'azureml.pipelineRun.moduleNodeId': 'ddf4899a', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/westcentralus/workspaces/2a594182-dd38-4bdd-b2db-551ef0f963d7/environments/experiment_env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220504.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=wBJI2Tc6VANEtawNnBCaPLzblbO0rh2zaKwt28LMWjE%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=iWyhxlwPVJ%2BbzQflw7F7ecDLze1JStcaU%2FPqwnYdPQE%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2022-06-22-14': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/dataprep/0/rslex.log.2022-06-22-14?sv=2019-07-07&sr=b&sig=6DirHs%2Fs3nVMWuQns70y9LPNzHdlRX%2FXBHVfiyFMnLQ%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=DL7pgPl6folyabfhLttYp9LrpYzbHoi3jBR1uV6lOxg%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=0XUxnchdRcWvZNu778KzWGpAUqjtd1BrRvw%2F%2Bsi%2BlPQ%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=12yA9Gm8jJ1kaaNtcYrlPrIe%2B1ogoSGz6S%2BggOPGkiY%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'user_logs/std_log.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=w7iZwOhKO%2Bq%2BJ7s0s6LAWPVL25jiSEfbOHmOHzTiOwU%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=kBXAJ2yqTPUBsdiKF2tz2s01SivnVGMcTi4eBBtIK4A%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=kn4lRDIOwEbecx5xrpP3IP2fn%2Bw8%2BQ%2FhZe%2BjOv3QXuY%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/data_capability/rslex.log.2022-06-22-14': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/data_capability/rslex.log.2022-06-22-14?sv=2019-07-07&sr=b&sig=BZOaaDmWIQcEjR%2FvwH7c46dFMNDDeFZv8a04p2AdeWQ%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=FTA7twZqPa3s0m%2BMi1LYjvpRNZ9cIG%2FrWN6Gi6pFk24%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=QWMyNcHy%2FiH1TRCuyWh4g9yEOKfi7zMyQo75L0mRCZM%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=djn85BL%2FyYhWSy4%2FWgrBsggGT2%2B3S2Rax2gSQk6jjko%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/lifecycler/vm-bootstrapper.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/lifecycler/vm-bootstrapper.log?sv=2019-07-07&sr=b&sig=oaQ4%2Fmc0v5%2F74%2BGGWD5sW%2FuJa0Hs5d1TUz6LAQPJjh4%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.3a5f6731-6997-4003-ae5f-d5e897f49918/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=4zJxK%2FfTqRVxTE4uzzySh%2BOte7Ibu07EyHqMtvFao7I%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A43%3A06Z&se=2022-06-22T22%3A53%3A06Z&sp=r'}, 'submittedBy': 'student-3727-1294131'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'c3aad46f-e2c0-49f5-9854-e2b3ff63c77d', 'status': 'Completed', 'startTimeUtc': '2022-06-22T14:48:17.889104Z', 'endTimeUtc': '2022-06-22T14:52:29.454931Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=xMaV2OLndJGZ7UNvgMDREQZco0wP%2BLpZWHj%2FfvWeVig%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A38%3A30Z&se=2022-06-22T22%3A48%3A30Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=FIhybamJq0jU33WMMzf9aMFVquS4L1EoEV5J6BCLsPI%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A38%3A30Z&se=2022-06-22T22%3A48%3A30Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabeah62qb7osjim.blob.core.windows.net/azureml/ExperimentRun/dcid.c3aad46f-e2c0-49f5-9854-e2b3ff63c77d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=XzoM6cqzBf6R0meNcDG%2ByCbw%2B0cEFs0UM1S0wKyGVqc%3D&skoid=13ee6612-f220-461c-ad45-a020cad5e0c3&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-22T13%3A43%3A56Z&ske=2022-06-23T21%3A53%3A56Z&sks=b&skv=2019-07-07&st=2022-06-22T14%3A38%3A30Z&se=2022-06-22T22%3A48%3A30Z&sp=r'}, 'submittedBy': 'student-3727-1294131'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655909591142
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the pipeline has finished, you can examine the metrics recorded by it's child runs."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\r\n",
        "    print(run.name, ':')\r\n",
        "    metrics = run.get_metrics()\r\n",
        "    for metric_name in metrics:\r\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train and Register Model :\n\t Accuracy : 0.8886666666666667\n\t AUC : 0.874635554007662\n\t ROC : aml://artifactId/ExperimentRun/dcid.a9744dfa-dc2c-4ee2-ab2f-297644385a95/ROC_1655909543.png\nPrepare Data :\n\t raw_rows : 10000\n\t processed_rows : 10000\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655909741419
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming the pipeline was successful, a new model should be registered with a Training context tag indicating it was trained in a pipeline. Run the following code to verify this."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 2\n\t Training context : Pipeline\n\t AUC : 0.874635554007662\n\t Accuracy : 0.8886666666666667\n\n\ndiabetes_model version: 1\n\t Training context : Pipeline\n\t AUC : 0.8793571819493506\n\t Accuracy : 0.8926666666666667\n\n\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655909742216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile $experiment_folder/deploy.py\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core import Workspace\r\n",
        "#from azureml.core.model import Model\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "from azureml.exceptions import WebserviceException\r\n",
        "import argparse\r\n",
        "\r\n",
        "#model=Model.get_model_path('diabetes_model')\r\n",
        "\r\n",
        "'''\r\n",
        "# Define arguments\r\n",
        "parser = argparse.ArgumentParser(description='Deploy arg parser')\r\n",
        "#parser.add_argument('--test_dir', type=str, help='Directory where testing data is stored')\r\n",
        "#parser.add_argument('--model_dir', type=str, help='File storing the evaluation accuracy')\r\n",
        "parser.add_argument(\"--model-dir\", type=str, dest='model_dir', help='model file')\r\n",
        "#parser.add_argument('--accuracy_dir', type=str, help='File storing the evaluation accuracy')\r\n",
        "\r\n",
        "args = parser.parse_args()\r\n",
        "'''\r\n",
        "# Get run context\r\n",
        "run = Run.get_context()\r\n",
        "#workspace = run.experiment.workspace\r\n",
        "\r\n",
        "#accuracy_dir = args.accuracy_dir\r\n",
        "#model_dir = args.model_dir\r\n",
        "\r\n",
        "'''\r\n",
        "if not os.path.exists(model_dir):\r\n",
        "    os.makedirs(model_dir)\r\n",
        "'''\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment(name='service-env')\r\n",
        "\r\n",
        "# Register environment to re-use later\r\n",
        "service_env.register(workspace = ws)\r\n",
        "\r\n",
        "# Service name\r\n",
        "service_name = \"diabetes-service\"\r\n",
        "\r\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\r\n",
        "for package in python_packages:\r\n",
        "    service_env.python.conda_dependencies.add_pip_package(package)\r\n",
        "\r\n",
        "\r\n",
        "# Models\r\n",
        "model_dir = ws.models['diabetes_model']\r\n",
        "\r\n",
        "new_model=True\r\n",
        "\r\n",
        "if new_model:\r\n",
        "    inference_config = InferenceConfig(source_directory=experiment_folder,\r\n",
        "                                    entry_script=\"score_diabetes.py\",\r\n",
        "                                    environment=service_env)\r\n",
        "\r\n",
        "    # Configure the web service container\r\n",
        "    deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "    try:\r\n",
        "        service=Webservice(ws,name=service_name)\r\n",
        "        if service:\r\n",
        "            service.delete()\r\n",
        "    except WebserviceException as e:\r\n",
        "        print()\r\n",
        "    # Deploy the model as a service\r\n",
        "    print('Deploying model...')\r\n",
        "\r\n",
        "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "    service.wait_for_deployment(True)\r\n",
        "else:\r\n",
        "    service = Webservice(ws, name=service_name)\r\n",
        "\r\n",
        "print(service.state)\r\n",
        "'''\r\n",
        "# Output scoring url to file\r\n",
        "print(service.scoring_uri)\r\n",
        "with open(model_dir + '/scoring_uri.txt', 'w+') as f:\r\n",
        "    f.write(service.scoring_uri)\r\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nDeploying model...\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-06-22 14:58:05+00:00 Creating Container Registry if not exists.\n2022-06-22 14:58:05+00:00 Registering the environment.\n2022-06-22 14:58:06+00:00 Building image..\n2022-06-22 15:08:21+00:00 Generating deployment configuration.\n2022-06-22 15:08:22+00:00 Submitting deployment to compute..\n2022-06-22 15:08:28+00:00 Checking the status of deployment diabetes-service..\n2022-06-22 15:09:54+00:00 Checking the status of inference endpoint diabetes-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "\"\\n# Output scoring url to file\\nprint(service.scoring_uri)\\nwith open(model_dir + '/scoring_uri.txt', 'w+') as f:\\n    f.write(service.scoring_uri)\\n\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910599827
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the pipeline\r\n",
        "After you've created and tested a pipeline, you can publish it as a REST service."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish the pipeline from the run\r\n",
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-training-pipeline,\nId: 5f5d0121-72ec-47e4-9098-1d62b5b265e6,\nStatus: Active,\nEndpoint: https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourceGroups/cal-3727-34/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-eah62qb7osjim/PipelineRuns/PipelineSubmit/5f5d0121-72ec-47e4-9098-1d62b5b265e6)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/5f5d0121-72ec-47e4-9098-1d62b5b265e6?wsid=/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourcegroups/cal-3727-34/workspaces/ml-lab-eah62qb7osjim\" target=\"_blank\" rel=\"noopener\">5f5d0121-72ec-47e4-9098-1d62b5b265e6</a></td><td>Active</td><td><a href=\"https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourceGroups/cal-3727-34/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-eah62qb7osjim/PipelineRuns/PipelineSubmit/5f5d0121-72ec-47e4-9098-1d62b5b265e6\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910656867
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the published pipeline has an endpoint, which you can see in the Endpoints page (on the Pipeline Endpoints tab) in Azure Machine Learning studio. You can also find its URI as a property of the published pipeline object:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/1180d7d2-bb0a-4c4a-8011-1a73b31a7318/resourceGroups/cal-3727-34/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-eah62qb7osjim/PipelineRuns/PipelineSubmit/5f5d0121-72ec-47e4-9098-1d62b5b265e6\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910665802
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Call the pipeline endpoint\r\n",
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "print(\"Authentication header ready.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910675865
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "\r\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, \r\n",
        "                         headers=auth_header, \r\n",
        "                         json={\"ExperimentName\": experiment_name})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "'dd07b553-ea1b-4fb4-b40c-18ffa0cac0bf'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910682857
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tab_data_set.take(1).to_pandas_dataframe().values.flatten().tolist()[0:9]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "[1354778.0, 0.0, 171.0, 80.0, 34.0, 23.0, 43.50972593, 1.213191354, 21.0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910728210
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data=tab_data_set.take(1).to_pandas_dataframe()[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values.flatten().tolist()\r\n",
        "new_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "[0.0, 171.0, 80.0, 34.0, 23.0, 43.50972593, 1.213191354, 21.0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655911585662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.scoring_uri"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "'http://e9fba7eb-d44b-4b9b-8c1c-3834172405c9.westcentralus.azurecontainer.io/score'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655910823715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import urllib.request, urllib.error # urllib.request and urllib.error for Python 3.X\r\n",
        "import json\r\n",
        "import requests\r\n",
        "#from azureml.core.webservice import Webservice\r\n",
        "\r\n",
        "# Iris petal and sepal measurements\r\n",
        "x_new =  [new_data]\r\n",
        "\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Get the URL of the web service\r\n",
        "#service = Webservice(workspace=ws, name='iris-classification-service')\r\n",
        "endpoint = service.scoring_uri\r\n",
        "\r\n",
        "# Send data to web service\r\n",
        "#body = str.encode(json.dumps(rawdata))\r\n",
        "\r\n",
        "# Set the content type\r\n",
        "headers = { 'Content-Type':'application/json' }\r\n",
        "\r\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\r\n",
        "predicted_classes = json.loads(predictions.json())\r\n",
        "\r\n",
        "for i in range(len(x_new)):\r\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Patient [0.0, 171.0, 80.0, 34.0, 23.0, 43.50972593, 1.213191354, 21.0] diabetic\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655911596810
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}