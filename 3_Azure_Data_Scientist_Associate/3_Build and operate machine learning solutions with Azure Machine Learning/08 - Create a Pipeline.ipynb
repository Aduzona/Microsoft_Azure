{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Pipeline\n",
        "\n",
        "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a *pipeline* that can be run on one or more compute targets; either on-demand by a user, from an automated build process, or on a schedule.\n",
        "\n",
        "In this notebook, you'll bring together all of these elements to create a simple pipeline that pre-processes data and then trains and registers a model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.41.0 to work with ml-lab-b4jqaft7eli2q\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1654688835614
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "In your pipeline, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if you created it previously, the code will find the existing version)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to diabetes-data/\nUploading an estimated of 4 files\nUploading data/.amlignore\nUploaded data/.amlignore, 1 files out of an estimated total of 4\nUploading data/.amlignore.amltmp\nUploaded data/.amlignore.amltmp, 2 files out of an estimated total of 4\nUploading data/diabetes.csv\nUploaded data/diabetes.csv, 3 files out of an estimated total of 4\nUploading data/diabetes2.csv\nUploaded data/diabetes2.csv, 4 files out of an estimated total of 4\nUploaded 4 files\nCreating new dataset\nDataset registered.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1654688923454
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create scripts for pipeline steps\n",
        "\n",
        "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like a data transfer step that copies data from one location to another. Each step can run in its own compute context. In this exercise, you'll build a simple pipeline that contains two Python script steps: one to pre-process some training data, and another to use the pre-processed data to train and register a model.\n",
        "\n",
        "First, let's create a folder for the script files we'll use in the pipeline steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_pipeline\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1654688945355
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create the first script, which will read data from the diabetes dataset and apply some simple pre-processing to remove any rows with missing data and normalize the numeric features so they're on a similar scale.\n",
        "\n",
        "The script includes a argument named **--prepped-data**, which references the folder where the resulting data should be saved."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/prep_diabetes.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can create the script for the second step, which will train a model. The script includes a argument named **--training-data**, which references the location where the prepared data was saved by the previous step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train adecision tree model\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/train_diabetes.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a compute environment for the pipeline steps\n",
        "\n",
        "In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
        "\n",
        "First, get the compute target you created in a previous lab (if it doesn't exist, it will be created).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"automl-compute\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1654689512029
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
        "\n",
        "The compute will require a Python environment with the necessary package dependencies installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.8\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing diabetes_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have a Conda configuration file, you can create an environment and use it in the run configuration for the pipeline."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1654690032723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and run a pipeline\n",
        "\n",
        "Now you're ready to create and run a pipeline.\n",
        "\n",
        "First you need to define the steps for the pipeline, and any data references that need to be passed between them. In this case, the first step must write the prepared data to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **OutputFileDatasetConfig** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1654690843142
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [0d5017c5][e6f9b511-7172-4c38-be79-1e81116712b5], (This step will run and generate new outputs)\nCreated step Train and Register Model [7153653e][e0bbf26a-f0f8-410b-9b4f-e06b114ca391], (This step will run and generate new outputs)\nSubmitted PipelineRun 6f805508-6544-416f-922c-359c4e0a183f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/6f805508-6544-416f-922c-359c4e0a183f?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb6333547b94c508f828c41374db282"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/6f805508-6544-416f-922c-359c4e0a183f?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\", \"run_id\": \"6f805508-6544-416f-922c-359c4e0a183f\", \"run_properties\": {\"run_id\": \"6f805508-6544-416f-922c-359c4e0a183f\", \"created_utc\": \"2022-06-08T12:23:04.149024Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-06-08T12:37:11.815818Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=PyZPCsix8AiFlt1W6kG1oK5Hf154F46H9BgZm0sQJnk%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A45%3A54Z&se=2022-06-08T20%3A55%3A54Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=UOW752SWRLj%2F4t%2F2ouojiocktNcxFbiIu5G%2BTKq4bR8%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A45%3A54Z&se=2022-06-08T20%3A55%3A54Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=rxf56BHE0ANz%2FeZ3IRoHTkfxckweYzTN1dg6k5ajIvM%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A45%3A54Z&se=2022-06-08T20%3A55%3A54Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:14:07\", \"run_number\": \"1654690984\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-06-08T12:35:44.296296Z\", \"created_time\": \"2022-06-08T12:23:06.633041Z\", \"end_time\": \"2022-06-08T12:36:47.605027Z\", \"duration\": \"0:13:40\", \"run_number\": 1654690986, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-08T12:23:06.633041Z\", \"is_reused\": \"\"}, {\"run_id\": \"0a325487-9e29-46c8-af79-e5d01faac9fa\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-06-08T12:36:57.15384Z\", \"created_time\": \"2022-06-08T12:36:49.728129Z\", \"end_time\": \"2022-06-08T12:37:10.802738Z\", \"duration\": \"0:00:21\", \"run_number\": 1654691809, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-08T12:36:49.728129Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-06-08 12:23:06Z] Submitting 1 runs, first five are: 0d5017c5:8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1\\n[2022-06-08 12:36:49Z] Completing processing run id 8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1.\\n[2022-06-08 12:36:49Z] Submitting 1 runs, first five are: 7153653e:0a325487-9e29-46c8-af79-e5d01faac9fa\\n[2022-06-08 12:37:11Z] Completing processing run id 0a325487-9e29-46c8-af79-e5d01faac9fa.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"a65dd378\": {\"node_id\": \"a65dd378\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"0d5017c5\": {\"node_id\": \"0d5017c5\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1\"}, \"7153653e\": {\"node_id\": \"7153653e\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0a325487-9e29-46c8-af79-e5d01faac9fa\"}}, \"edges\": [{\"source_node_id\": \"a65dd378\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"0d5017c5\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"0d5017c5\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_358aaeac\", \"dst_node_id\": \"7153653e\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-06-08T12:35:44.296296Z\", \"created_time\": \"2022-06-08T12:23:06.633041Z\", \"end_time\": \"2022-06-08T12:36:47.605027Z\", \"duration\": \"0:13:40\", \"run_number\": 1654690986, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-08T12:23:06.633041Z\", \"is_reused\": \"\"}, {\"run_id\": \"0a325487-9e29-46c8-af79-e5d01faac9fa\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-06-08T12:36:57.15384Z\", \"created_time\": \"2022-06-08T12:36:49.728129Z\", \"end_time\": \"2022-06-08T12:37:10.802738Z\", \"duration\": \"0:00:21\", \"run_number\": 1654691809, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-06-08T12:36:49.728129Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 6f805508-6544-416f-922c-359c4e0a183f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/6f805508-6544-416f-922c-359c4e0a183f?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nPipelineRun Status: Running\n\n\nStepRunId: 8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nStepRun( Prepare Data ) Status: Running\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n2022/06/08 12:23:19 Downloading source code...\n2022/06/08 12:23:20 Finished downloading source code\n2022/06/08 12:23:21 Creating Docker network: acb_default_network, driver: 'bridge'\n2022/06/08 12:23:21 Successfully set up Docker network: acb_default_network\n2022/06/08 12:23:21 Setting up Docker configuration...\n2022/06/08 12:23:21 Successfully set up Docker configuration\n2022/06/08 12:23:21 Logging in to registry: 847c158af05f4ebb8850171f11997d8d.azurecr.io\n2022/06/08 12:23:22 Successfully logged into 847c158af05f4ebb8850171f11997d8d.azurecr.io\n2022/06/08 12:23:22 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/06/08 12:23:22 Scanning for dependencies...\n2022/06/08 12:23:23 Successfully scanned dependencies\n2022/06/08 12:23:23 Launching container with name: acb_step_0\nSending build context to Docker daemon  66.56kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\nmcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n08a6abff8943: Pulling fs layer\n3fc933ffb1b7: Pulling fs layer\nac93e58c5dc7: Pulling fs layer\n5dcdef402503: Pulling fs layer\nbbf579d09b2f: Pulling fs layer\n4561d7db36b6: Pulling fs layer\nd112deec94d8: Pulling fs layer\nf8fe34184935: Pulling fs layer\n805a516c439d: Pulling fs layer\n5dcdef402503: Waiting\nbbf579d09b2f: Waiting\n4561d7db36b6: Waiting\nd112deec94d8: Waiting\nf8fe34184935: Waiting\n805a516c439d: Waiting\nac93e58c5dc7: Verifying Checksum\nac93e58c5dc7: Download complete\n5dcdef402503: Verifying Checksum\n5dcdef402503: Download complete\n08a6abff8943: Verifying Checksum\n08a6abff8943: Download complete\n3fc933ffb1b7: Verifying Checksum\n3fc933ffb1b7: Download complete\n4561d7db36b6: Verifying Checksum\n4561d7db36b6: Download complete\nf8fe34184935: Verifying Checksum\nf8fe34184935: Download complete\nd112deec94d8: Verifying Checksum\nd112deec94d8: Download complete\n805a516c439d: Verifying Checksum\n805a516c439d: Download complete\nbbf579d09b2f: Verifying Checksum\nbbf579d09b2f: Download complete\n08a6abff8943: Pull complete\n3fc933ffb1b7: Pull complete\nac93e58c5dc7: Pull complete\n5dcdef402503: Pull complete\nbbf579d09b2f: Pull complete\n4561d7db36b6: Pull complete\nd112deec94d8: Pull complete\nf8fe34184935: Pull complete\n805a516c439d: Pull complete\nDigest: sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1@sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\n ---> b2db557fb48e\nStep 2/21 : USER root\n ---> Running in 4374ac66369c\nRemoving intermediate container 4374ac66369c\n ---> cfa6a2541b3b\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in c339c8acc925\nRemoving intermediate container c339c8acc925\n ---> 17bf637a3338\nStep 4/21 : WORKDIR /\n ---> Running in d5de519354f1\nRemoving intermediate container d5de519354f1\n ---> 81d68aa79e9c\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> 617b38027482\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in deabd7b43553\nRemoving intermediate container deabd7b43553\n ---> 537573a28377\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 311e73688758\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in fd1570b88353\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nncurses-6.3          | 782 KB    |            |   0% \nncurses-6.3          | 782 KB    | 2          |   2% \nncurses-6.3          | 782 KB    | ######9    |  70% \nncurses-6.3          | 782 KB    | ########## | 100% \nncurses-6.3          | 782 KB    | ########## | 100% \n\nsix-1.16.0           | 18 KB     |            |   0% \nsix-1.16.0           | 18 KB     | ########## | 100% \n\ntraitlets-5.1.1      | 84 KB     |            |   0% \ntraitlets-5.1.1      | 84 KB     | ########## | 100% \n\nmatplotlib-inline-0. | 12 KB     |            |   0% \nmatplotlib-inline-0. | 12 KB     | ########## | 100% \n\nqt-5.9.7             | 68.5 MB   |            |   0% \nqt-5.9.7             | 68.5 MB   | 1          |   1% \nqt-5.9.7             | 68.5 MB   | #1         |  11% \nqt-5.9.7             | 68.5 MB   | ##4        |  25% \nqt-5.9.7             | 68.5 MB   | ###9       |  39% \nqt-5.9.7             | 68.5 MB   | #####2     |  52% \nqt-5.9.7             | 68.5 MB   | ######6    |  67% \nqt-5.9.7             | 68.5 MB   | ########   |  81% \nqt-5.9.7             | 68.5 MB   | #########5 |  95% \nqt-5.9.7             | 68.5 MB   | ########## | 100% \n\ntk-8.6.12            | 3.0 MB    |            |   0% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \ntk-8.6.12            | 3.0 MB    | ########## | 100% \n\nintel-openmp-2021.4. | 4.2 MB    |            |   0% \nintel-openmp-2021.4. | 4.2 MB    | #########  |  90% \nintel-openmp-2021.4. | 4.2 MB    | ########## | 100% \n\ndebugpy-1.5.1        | 1.7 MB    |            |   0% \ndebugpy-1.5.1        | 1.7 MB    | ########## | 100% \ndebugpy-1.5.1        | 1.7 MB    | ########## | 100% \n\ntornado-6.1          | 588 KB    |            |   0% \ntornado-6.1          | 588 KB    | ########## | 100% \n\nnumpy-1.22.3         | 10 KB     |            |   0% \nnumpy-1.22.3         | 10 KB     | ########## | 100% \n\npickleshare-0.7.5    | 13 KB     |            |   0% \npickleshare-0.7.5    | 13 KB     | ########## | 100% \n\njoblib-1.1.0         | 211 KB    |            |   0% \njoblib-1.1.0         | 211 KB    | ########## | 100% \n\npandas-1.4.2         | 9.9 MB    |            |   0% \npandas-1.4.2         | 9.9 MB    | #####3     |  54% \npandas-1.4.2         | 9.9 MB    | ########## | 100% \npandas-1.4.2         | 9.9 MB    | ########## | 100% \n\nlz4-c-1.9.3          | 185 KB    |            |   0% \nlz4-c-1.9.3          | 185 KB    | ########## | 100% \n\nlibxcb-1.15          | 505 KB    |            |   0% \nlibxcb-1.15          | 505 KB    | ########## | 100% \n\nlibgfortran4-7.5.0   | 995 KB    |            |   0% \nlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \n\npyparsing-3.0.4      | 81 KB     |            |   0% \npyparsing-3.0.4      | 81 KB     | ########## | 100% \n\nsetuptools-61.2.0    | 1012 KB   |            |   0% \nsetuptools-61.2.0    | 1012 KB   | ########## | 100% \nsetuptools-61.2.0    | 1012 KB   | ########## | 100% \n\nmkl_fft-1.3.1        | 180 KB    |            |   0% \nmkl_fft-1.3.1        | 180 KB    | ########## | 100% \n\nprompt-toolkit-3.0.2 | 259 KB    |            |   0% \nprompt-toolkit-3.0.2 | 259 KB    | ########## | 100% \n\nopenssl-1.1.1o       | 2.5 MB    |            |   0% \nopenssl-1.1.1o       | 2.5 MB    | ########## | 100% \nopenssl-1.1.1o       | 2.5 MB    | ########## | 100% \n\nmunkres-1.1.4        | 13 KB     |            |   0% \nmunkres-1.1.4        | 13 KB     | ########## | 100% \n\npyzmq-22.3.0         | 476 KB    |            |   0% \npyzmq-22.3.0         | 476 KB    | ########## | 100% \n\nmkl_random-1.2.2     | 308 KB    |            |   0% \nmkl_random-1.2.2     | 308 KB    | ########## | 100% \n\nentrypoints-0.4      | 16 KB     |            |   0% \nentrypoints-0.4      | 16 KB     | ########## | 100% \n\npillow-9.0.1         | 659 KB    |            |   0% \npillow-9.0.1         | 659 KB    | ########## | 100% \n\nmatplotlib-base-3.5. | 5.7 MB    |            |   0% \nmatplotlib-base-3.5. | 5.7 MB    | #########2 |  93% \nmatplotlib-base-3.5. | 5.7 MB    | ########## | 100% \n\nexecuting-0.8.3      | 18 KB     |            |   0% \nexecuting-0.8.3      | 18 KB     | ########## | 100% \n\nbackcall-0.2.0       | 13 KB     |            |   0% \nbackcall-0.2.0       | 13 KB     | ########## | 100% \n\npexpect-4.8.0        | 53 KB     |            |   0% \npexpect-4.8.0        | 53 KB     | ########## | 100% \n\nlibgomp-11.2.0       | 474 KB    |            |   0% \nlibgomp-11.2.0       | 474 KB    | ########## | 100% \n\npytz-2021.3          | 171 KB    |            |   0% \npytz-2021.3          | 171 KB    | ########## | 100% \n\npyqt-5.9.2           | 4.5 MB    |            |   0% \npyqt-5.9.2           | 4.5 MB    | #########6 |  97% \npyqt-5.9.2           | 4.5 MB    | ########## | 100% \n\ndbus-1.13.18         | 504 KB    |            |   0% \ndbus-1.13.18         | 504 KB    | ########## | 100% \n\nsip-4.19.13          | 279 KB    |            |   0% \nsip-4.19.13          | 279 KB    | ########## | 100% \n\nsqlite-3.38.3        | 1.0 MB    |            |   0% \nsqlite-3.38.3        | 1.0 MB    | ########## | 100% \n\nstack_data-0.2.0     | 22 KB     |            |   0% \nstack_data-0.2.0     | 22 KB     | ########## | 100% \n\nnest-asyncio-1.5.5   | 16 KB     |            |   0% \nnest-asyncio-1.5.5   | 16 KB     | ########## | 100% \n\njupyter_core-4.10.0  | 76 KB     |            |   0% \njupyter_core-4.10.0  | 76 KB     | ########## | 100% \n\njupyter_client-7.2.2 | 191 KB    |            |   0% \njupyter_client-7.2.2 | 191 KB    | ########## | 100% \n\nbottleneck-1.3.4     | 127 KB    |            |   0% \nbottleneck-1.3.4     | 127 KB    | ########## | 100% \n\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########2  |  83% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \n\nld_impl_linux-64-2.3 | 654 KB    |            |   0% \nld_impl_linux-64-2.3 | 654 KB    | ########## | 100% \n\nbrotli-1.0.9         | 375 KB    |            |   0% \nbrotli-1.0.9         | 375 KB    | ########## | 100% \n\nxz-5.2.5             | 339 KB    |            |   0% \nxz-5.2.5             | 339 KB    | ########## | 100% \n\ndecorator-5.1.1      | 12 KB     |            |   0% \ndecorator-5.1.1      | 12 KB     | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \n\ngstreamer-1.14.0     | 3.2 MB    |            |   0% \ngstreamer-1.14.0     | 3.2 MB    | ########## | 100% \ngstreamer-1.14.0     | 3.2 MB    | ########## | 100% \n\ncycler-0.11.0        | 12 KB     |            |   0% \ncycler-0.11.0        | 12 KB     | ########## | 100% \n\npure_eval-0.2.2      | 14 KB     |            |   0% \npure_eval-0.2.2      | 14 KB     | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\nmkl-service-2.4.0    | 59 KB     |            |   0% \nmkl-service-2.4.0    | 59 KB     | ########## | 100% \n\nparso-0.8.3          | 70 KB     |            |   0% \nparso-0.8.3          | 70 KB     | ########## | 100% \n\nlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \nlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n\nwcwidth-0.2.5        | 26 KB     |            |   0% \nwcwidth-0.2.5        | 26 KB     | ########## | 100% \n\nlibuuid-1.0.3        | 17 KB     |            |   0% \nlibuuid-1.0.3        | 17 KB     | ########## | 100% \n\ngiflib-5.2.1         | 78 KB     |            |   0% \ngiflib-5.2.1         | 78 KB     | ########## | 100% \n\nmatplotlib-3.5.1     | 29 KB     |            |   0% \nmatplotlib-3.5.1     | 29 KB     | ########## | 100% \n\nzlib-1.2.12          | 106 KB    |            |   0% \nzlib-1.2.12          | 106 KB    | ########## | 100% \n\nlibsodium-1.0.18     | 244 KB    |            |   0% \nlibsodium-1.0.18     | 244 KB    | ########## | 100% \n\nlibtiff-4.2.0        | 452 KB    |            |   0% \nlibtiff-4.2.0        | 452 KB    | ########## | 100% \n\nca-certificates-2022 | 124 KB    |            |   0% \nca-certificates-2022 | 124 KB    | ########## | 100% \n\nzstd-1.5.2           | 488 KB    |            |   0% \nzstd-1.5.2           | 488 KB    | ########## | 100% \n\nlibffi-3.3           | 50 KB     |            |   0% \nlibffi-3.3           | 50 KB     | ########## | 100% \n\npython-dateutil-2.8. | 233 KB    |            |   0% \npython-dateutil-2.8. | 233 KB    | ########## | 100% \n\nlibwebp-base-1.2.2   | 440 KB    |            |   0% \nlibwebp-base-1.2.2   | 440 KB    | ########## | 100% \n\npackaging-21.3       | 36 KB     |            |   0% \npackaging-21.3       | 36 KB     | ########## | 100% \n\nblas-1.0             | 6 KB      |            |   0% \nblas-1.0             | 6 KB      | ########## | 100% \n\nlibxml2-2.9.14       | 718 KB    |            |   0% \nlibxml2-2.9.14       | 718 KB    | ########## | 100% \n\nipython-8.3.0        | 963 KB    |            |   0% \nipython-8.3.0        | 963 KB    | ########## | 100% \nipython-8.3.0        | 963 KB    | ########## | 100% \n\nfonttools-4.25.0     | 632 KB    |            |   0% \nfonttools-4.25.0     | 632 KB    | ########## | 100% \n\nfontconfig-2.13.1    | 250 KB    |            |   0% \nfontconfig-2.13.1    | 250 KB    | ########## | 100% \n\n_openmp_mutex-5.1    | 21 KB     |            |   0% \n_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n\njpeg-9e              | 240 KB    |            |   0% \njpeg-9e              | 240 KB    | ########## | 100% \n\nipykernel-6.9.1      | 199 KB    |            |   0% \nipykernel-6.9.1      | 199 KB    | ########## | 100% \n\nexpat-2.4.4          | 169 KB    |            |   0% \nexpat-2.4.4          | 169 KB    | ########## | 100% \n\nptyprocess-0.7.0     | 17 KB     |            |   0% \nptyprocess-0.7.0     | 17 KB     | ########## | 100% \n\nglib-2.69.1          | 1.7 MB    |            |   0% \nglib-2.69.1          | 1.7 MB    | ########## | 100% \nglib-2.69.1          | 1.7 MB    | ########## | 100% \n\nscipy-1.7.3          | 16.6 MB   |            |   0% \nscipy-1.7.3          | 16.6 MB   | ##5        |  25% \nscipy-1.7.3          | 16.6 MB   | ########4  |  85% \nscipy-1.7.3          | 16.6 MB   | ########## | 100% \n\nthreadpoolctl-2.2.0  | 16 KB     |            |   0% \nthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n\nwheel-0.37.1         | 33 KB     |            |   0% \nwheel-0.37.1         | 33 KB     | ########## | 100% \n\njedi-0.18.1          | 982 KB    |            |   0% \njedi-0.18.1          | 982 KB    | ########## | 100% \njedi-0.18.1          | 982 KB    | ########## | 100% \n\nlibwebp-1.2.2        | 80 KB     |            |   0% \nlibwebp-1.2.2        | 80 KB     | ########## | 100% \n\nmkl-2021.4.0         | 142.6 MB  |            |   0% \nmkl-2021.4.0         | 142.6 MB  | 2          |   3% \nmkl-2021.4.0         | 142.6 MB  | 9          |   9% \nmkl-2021.4.0         | 142.6 MB  | #5         |  15% \nmkl-2021.4.0         | 142.6 MB  | ##2        |  22% \nmkl-2021.4.0         | 142.6 MB  | ##8        |  28% \nmkl-2021.4.0         | 142.6 MB  | ###5       |  35% \nmkl-2021.4.0         | 142.6 MB  | ####1      |  42% \nmkl-2021.4.0         | 142.6 MB  | ####8      |  49% \nmkl-2021.4.0         | 142.6 MB  | #####5     |  56% \nmkl-2021.4.0         | 142.6 MB  | ######3    |  63% \nmkl-2021.4.0         | 142.6 MB  | #######    |  70% \nmkl-2021.4.0         | 142.6 MB  | #######6   |  77% \nmkl-2021.4.0         | 142.6 MB  | ########3  |  84% \nmkl-2021.4.0         | 142.6 MB  | #########  |  91% \nmkl-2021.4.0         | 142.6 MB  | #########7 |  98% \nmkl-2021.4.0         | 142.6 MB  | ########## | 100% \n\nfreetype-2.11.0      | 618 KB    |            |   0% \nfreetype-2.11.0      | 618 KB    | ########## | 100% \n\nscikit-learn-1.0.2   | 5.6 MB    |            |   0% \nscikit-learn-1.0.2   | 5.6 MB    | ##5        |  26% \nscikit-learn-1.0.2   | 5.6 MB    | ########## | 100% \nscikit-learn-1.0.2   | 5.6 MB    | ########## | 100% \n\nasttokens-2.0.5      | 20 KB     |            |   0% \nasttokens-2.0.5      | 20 KB     | ########## | 100% \n\nlibpng-1.6.37        | 278 KB    |            |   0% \nlibpng-1.6.37        | 278 KB    | ########## | 100% \n\npcre-8.45            | 207 KB    |            |   0% \npcre-8.45            | 207 KB    | ########## | 100% \n\npython-3.8.13        | 18.8 MB   |            |   0% \npython-3.8.13        | 18.8 MB   | #4         |  14% \npython-3.8.13        | 18.8 MB   | #####8     |  59% \npython-3.8.13        | 18.8 MB   | ########## | 100% \npython-3.8.13        | 18.8 MB   | ########## | 100% \n\ncertifi-2022.5.18.1  | 147 KB    |            |   0% \ncertifi-2022.5.18.1  | 147 KB    | ########## | 100% \n\nnumpy-base-1.22.3    | 5.4 MB    |            |   0% \nnumpy-base-1.22.3    | 5.4 MB    | ####       |  40% \nnumpy-base-1.22.3    | 5.4 MB    | ########## | 100% \nnumpy-base-1.22.3    | 5.4 MB    | ########## | 100% \n\nicu-58.2             | 10.5 MB   |            |   0% \nicu-58.2             | 10.5 MB   | #3         |  14% \nicu-58.2             | 10.5 MB   | #######3   |  73% \nicu-58.2             | 10.5 MB   | ########## | 100% \nicu-58.2             | 10.5 MB   | ########## | 100% \n\nnumexpr-2.8.1        | 125 KB    |            |   0% \nnumexpr-2.8.1        | 125 KB    | ########## | 100% \n\ngst-plugins-base-1.1 | 4.9 MB    |            |   0% \ngst-plugins-base-1.1 | 4.9 MB    | ####       |  40% \ngst-plugins-base-1.1 | 4.9 MB    | ########## | 100% \ngst-plugins-base-1.1 | 4.9 MB    | ########## | 100% \n\nlcms2-2.12           | 312 KB    |            |   0% \nlcms2-2.12           | 312 KB    | ########## | 100% \n\nkiwisolver-1.4.2     | 83 KB     |            |   0% \nkiwisolver-1.4.2     | 83 KB     | ########## | 100% \n\npip-21.2.4           | 1.8 MB    |            |   0% \npip-21.2.4           | 1.8 MB    | ########## | 100% \npip-21.2.4           | 1.8 MB    | ########## | 100% \n\nzeromq-4.3.4         | 331 KB    |            |   0% \nzeromq-4.3.4         | 331 KB    | ########## | 100% \n\nreadline-8.1.2       | 354 KB    |            |   0% \nreadline-8.1.2       | 354 KB    | ########## | 100% \n\npygments-2.11.2      | 759 KB    |            |   0% \npygments-2.11.2      | 759 KB    | ########## | 100% \npygments-2.11.2      | 759 KB    | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \n\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n    More details are available here: https://intel.github.io/scikit-learn-intelex\n\n    For example:\n\n        $ conda install scikit-learn-intelex\n        $ python -m sklearnex my_application.py\n\n    \n\ndone\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.3bu14dod.requirements.txt']\nPip subprocess output:\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.42.0-py3-none-any.whl (2.0 kB)\nCollecting pyarrow\n  Downloading pyarrow-8.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\nCollecting azureml-inference-server-http~=0.4.1\n  Downloading azureml_inference_server_http-0.4.13-py3-none-any.whl (39 kB)\nCollecting azureml-core~=1.42.0\n  Downloading azureml_core-1.42.0.post1-py3-none-any.whl (2.7 MB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.42.0\n  Downloading azureml_dataset_runtime-1.42.0-py3-none-any.whl (2.2 kB)\nRequirement already satisfied: numpy>=1.16.6 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 2)) (1.22.3)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\nRequirement already satisfied: packaging<22.0,>=20.0 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (21.3)\nCollecting knack~=0.9.0\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\nCollecting azure-core<=1.22.1\n  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\nCollecting urllib3<=1.26.9,>=1.23\n  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nRequirement already satisfied: pytz in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (2021.3)\nCollecting azure-mgmt-resource<=21.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.0.0-py3-none-any.whl (2.3 MB)\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (2.8.2)\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting jmespath<=1.0.0\n  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\nCollecting azure-mgmt-containerregistry<10,>=8.2.0\n  Downloading azure_mgmt_containerregistry-9.1.0-py3-none-any.whl (1.1 MB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\nCollecting msrest<0.7.0,>=0.5.1\n  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\nCollecting docker<6.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from azure-core<=1.22.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (1.16.0)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\nCollecting pyarrow\n  Downloading pyarrow-3.0.0-cp38-cp38-manylinux2014_x86_64.whl (20.7 MB)\nCollecting azureml-dataprep<4.1.0a,>=4.0.0a\n  Downloading azureml_dataprep-4.0.3-py3-none-any.whl (43.4 MB)\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\nCollecting azureml-dataprep-rslex~=2.6.0dev0\n  Downloading azureml_dataprep_rslex-2.6.3-cp38-cp38-manylinux1_x86_64.whl (15.5 MB)\nCollecting jsonschema\n  Downloading jsonschema-4.6.0-py3-none-any.whl (80 kB)\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting inference-schema==1.3.0\n  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.4-py2.py3-none-any.whl (40 kB)\nCollecting Werkzeug<2.0,>=0.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\nCollecting Jinja2<3.1,>=2.10.1\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting applicationinsights>=0.11.7\n  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\nCollecting click<8.0,>=5.1\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting itsdangerous<2.0,>=0.24\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\nCollecting flask==1.0.3\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (61.2.0)\nCollecting wrapt<=1.12.1,>=1.11.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nRequirement already satisfied: pygments in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from knack~=0.9.0->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (2.11.2)\nCollecting tabulate\n  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from msrest<0.7.0,>=0.5.1->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (2022.5.18.1)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting opencensus<1.0.0,>=0.8.0\n  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (284 kB)\nCollecting opencensus-context>=0.1.2\n  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\nCollecting protobuf<4.0.0dev,>=3.15.0\n  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\nCollecting google-auth<3.0dev,>=1.25.0\n  Downloading google_auth-2.7.0-py2.py3-none-any.whl (160 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.8-py3-none-any.whl (39 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages (from packaging<22.0,>=20.0->azureml-core~=1.42.0->azureml-defaults->-r /azureml-environment-setup/condaenv.3bu14dod.requirements.txt (line 1)) (3.0.4)\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n  Downloading pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\nCollecting importlib-resources>=1.4.0\n  Downloading importlib_resources-5.7.1-py3-none-any.whl (28 kB)\nCollecting zipp>=3.1.0\n  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=26209f0f1a80f964d7d37d082fb900d36f638fc963ef97aef7e0dce4a3d36922\n  Stored in directory: /root/.cache/pip/wheels/e9/d6/70/7491901d808e74dd9238e4a91658ba108e4b5939b55327e6fb\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=08b4452b1ca65b283cde129d3f2f81c1eb68b619c6e29fea1422a32209f40159\n  Stored in directory: /root/.cache/pip/wheels/7f/41/10/f70b83a1164fdb95e7bc37bace13114a024227e56c2fee02bb\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=77993 sha256=e5dcbe81d91db25d38c11ef1cc03b2cdd06a9ac1dac21fafd32ff3b7929cb224\n  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\nSuccessfully built json-logging-py fusepy wrapt\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, requests, pyasn1, zipp, rsa, pyasn1-modules, protobuf, portalocker, oauthlib, msal, cachetools, requests-oauthlib, pyrsistent, msal-extensions, isodate, importlib-resources, googleapis-common-protos, google-auth, distro, azure-core, attrs, pyyaml, opencensus-context, msrest, MarkupSafe, jsonschema, google-api-core, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, Werkzeug, websocket-client, tabulate, PySocks, pyopenssl, pynacl, pyarrow, psutil, opencensus, msrestazure, jmespath, Jinja2, jeepney, itsdangerous, click, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, opencensus-ext-azure, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.1.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.2 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 attrs-21.4.0 azure-common-1.1.28 azure-core-1.22.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-9.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-21.0.0 azure-mgmt-storage-20.0.0 azureml-core-1.42.0.post1 azureml-dataprep-4.0.3 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.6.3 azureml-dataset-runtime-1.42.0 azureml-defaults-1.42.0 azureml-inference-server-http-0.4.13 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.2 cachetools-5.2.0 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 cryptography-36.0.2 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 flask-1.0.3 fusepy-3.0.1 google-api-core-2.8.1 google-auth-2.7.0 googleapis-common-protos-1.56.2 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 importlib-resources-5.7.1 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.8.0 jmespath-1.0.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-4.6.0 knack-0.9.0 msal-1.18.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.9.0 opencensus-context-0.1.2 opencensus-ext-azure-1.1.4 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.4.0 protobuf-3.20.1 psutil-5.9.1 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pynacl-1.5.0 pyopenssl-22.0.0 pyrsistent-0.18.1 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tabulate-0.8.9 urllib3-1.26.9 websocket-client-1.3.2 wrapt-1.12.1 zipp-3.8.0\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.9.2\n  latest version: 4.13.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0mWARNING: /root/.conda/pkgs does not exist\n\nRemoving intermediate container fd1570b88353\n ---> 80098d02a022\nStep 9/21 : ENV PATH /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin:$PATH\n ---> Running in dabdb3252105\nRemoving intermediate container dabdb3252105\n ---> b6a102b1a37e\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> 8e900ac9f6cc\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in a8512fc40a15\nCopying environment context\nRemoving intermediate container a8512fc40a15\n ---> 4f2957302b6e\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> 815d4821f6aa\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe\n ---> Running in c8950fe3cd88\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container c8950fe3cd88\n ---> a1ebc3113c7c\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe\n ---> Running in 851432d98a30\nRemoving intermediate container 851432d98a30\n ---> 5f5e06591001\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib:$LD_LIBRARY_PATH\n ---> Running in 2d73d6c4ad79\nRemoving intermediate container 2d73d6c4ad79\n ---> 640ce0bb7bd0\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_f102ca25577426a3b1fe82a38ab699fe CONDA_PREFIX=/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe\n ---> Running in 9ebe8458cf6e\nRemoving intermediate container 9ebe8458cf6e\n ---> f555fa6c94e3\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> 4ce4bdb838c1\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in dca7526238df\nRemoving intermediate container dca7526238df\n ---> c2530acceb75\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in 1972d4a8119d\nRemoving intermediate container 1972d4a8119d\n ---> d90ca861862d\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 33b822f6936c\nRemoving intermediate container 33b822f6936c\n ---> 8b969beca1fb\nStep 21/21 : CMD [\"bash\"]\n ---> Running in 3e4e45cd16cb\nRemoving intermediate container 3e4e45cd16cb\n ---> 19bc59303048\nSuccessfully built 19bc59303048\nSuccessfully tagged 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:latest\nSuccessfully tagged 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:1\n2022/06/08 12:26:04 Successfully executed container: acb_step_0\n2022/06/08 12:26:04 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/06/08 12:26:04 Pushing image: 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:1, attempt 1\nThe push refers to repository [847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058]\ne8563a2ee3f5: Preparing\n838590ede8c9: Preparing\n8c97d359bf7d: Preparing\n78572c406283: Preparing\nf7b24e5ecc36: Preparing\n8cb8b2b19e7e: Preparing\n7cd75b586173: Preparing\n2f292abbf866: Preparing\n8aa59dec806a: Preparing\nc8774954d4d3: Preparing\n8309ec71544b: Preparing\n656ad8e85648: Preparing\n2b5302f964e5: Preparing\n3a492541b73f: Preparing\nbc9cb95f9a70: Preparing\n5d01d1756548: Preparing\nd71f4c19e4b9: Preparing\n3f7a31c70acb: Preparing\n95c443da13bf: Preparing\n8cb8b2b19e7e: Waiting\n7cd75b586173: Waiting\n2f292abbf866: Waiting\n8aa59dec806a: Waiting\nc8774954d4d3: Waiting\n8309ec71544b: Waiting\n656ad8e85648: Waiting\n2b5302f964e5: Waiting\n3a492541b73f: Waiting\nbc9cb95f9a70: Waiting\n5d01d1756548: Waiting\nd71f4c19e4b9: Waiting\n3f7a31c70acb: Waiting\n95c443da13bf: Waiting\nf7b24e5ecc36: Pushed\n838590ede8c9: Pushed\ne8563a2ee3f5: Pushed\n78572c406283: Pushed\n8aa59dec806a: Pushed\n8c97d359bf7d: Pushed\n7cd75b586173: Pushed\n2f292abbf866: Pushed\n8309ec71544b: Pushed\nc8774954d4d3: Pushed\n656ad8e85648: Pushed\n2b5302f964e5: Pushed\n5d01d1756548: Pushed\n3a492541b73f: Pushed\nd71f4c19e4b9: Pushed\nbc9cb95f9a70: Pushed\n95c443da13bf: Pushed\n\n3f7a31c70acb: Pushed\n8cb8b2b19e7e: Pushed\n1: digest: sha256:1954ca67f02627fdccf0ac2626bbef46c781f9975676ad744adc811a59892b20 size: 4306\n2022/06/08 12:28:04 Successfully pushed image: 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:1\n2022/06/08 12:28:04 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/06/08 12:28:04 Pushing image: 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:latest, attempt 1\nThe push refers to repository [847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058]\ne8563a2ee3f5: Preparing\n838590ede8c9: Preparing\n8c97d359bf7d: Preparing\n78572c406283: Preparing\nf7b24e5ecc36: Preparing\n8cb8b2b19e7e: Preparing\n7cd75b586173: Preparing\n2f292abbf866: Preparing\n8aa59dec806a: Preparing\nc8774954d4d3: Preparing\n8309ec71544b: Preparing\n656ad8e85648: Preparing\n2b5302f964e5: Preparing\n3a492541b73f: Preparing\nbc9cb95f9a70: Preparing\n5d01d1756548: Preparing\nd71f4c19e4b9: Preparing\n3f7a31c70acb: Preparing\n95c443da13bf: Preparing\n8cb8b2b19e7e: Waiting\n7cd75b586173: Waiting\n2f292abbf866: Waiting\n8aa59dec806a: Waiting\nc8774954d4d3: Waiting\n8309ec71544b: Waiting\n656ad8e85648: Waiting\n2b5302f964e5: Waiting\n3a492541b73f: Waiting\nbc9cb95f9a70: Waiting\n5d01d1756548: Waiting\nd71f4c19e4b9: Waiting\n3f7a31c70acb: Waiting\n95c443da13bf: Waiting\n78572c406283: Layer already exists\ne8563a2ee3f5: Layer already exists\n8cb8b2b19e7e: Layer already exists\nf7b24e5ecc36: Layer already exists\n8c97d359bf7d: Layer already exists\n838590ede8c9: Layer already exists\n7cd75b586173: Layer already exists\n8aa59dec806a: Layer already exists\nc8774954d4d3: Layer already exists\n656ad8e85648: Layer already exists\n2f292abbf866: Layer already exists\n8309ec71544b: Layer already exists\n2b5302f964e5: Layer already exists\nbc9cb95f9a70: Layer already exists\n3a492541b73f: Layer already exists\nd71f4c19e4b9: Layer already exists\n5d01d1756548: Layer already exists\n3f7a31c70acb: Layer already exists\n95c443da13bf: Layer already exists\nlatest: digest: sha256:1954ca67f02627fdccf0ac2626bbef46c781f9975676ad744adc811a59892b20 size: 4306\n2022/06/08 12:28:07 Successfully pushed image: 847c158af05f4ebb8850171f11997d8d.azurecr.io/azureml/azureml_1c7f76878e8a1f787ef33582b68b8058:latest\n2022/06/08 12:28:07 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 161.459339)\n2022/06/08 12:28:07 Populating digests for step ID: acb_step_0...\n2022/06/08 12:28:08 Successfully populated digests for step ID: acb_step_0\n2022/06/08 12:28:08 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 120.633831)\n2022/06/08 12:28:08 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.326211)\n2022/06/08 12:28:08 The following dependencies were found:\n2022/06/08 12:28:08 \n- image:\n    registry: 847c158af05f4ebb8850171f11997d8d.azurecr.io\n    repository: azureml/azureml_1c7f76878e8a1f787ef33582b68b8058\n    tag: latest\n    digest: sha256:1954ca67f02627fdccf0ac2626bbef46c781f9975676ad744adc811a59892b20\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi3.1.2-ubuntu18.04\n    tag: 20220412.v1\n    digest: sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\n  git: {}\n- image:\n    registry: 847c158af05f4ebb8850171f11997d8d.azurecr.io\n    repository: azureml/azureml_1c7f76878e8a1f787ef33582b68b8058\n    tag: \"1\"\n    digest: sha256:1954ca67f02627fdccf0ac2626bbef46c781f9975676ad744adc811a59892b20\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi3.1.2-ubuntu18.04\n    tag: 20220412.v1\n    digest: sha256:7b2748bbf455a2d5adc8dd5af3c5c7890a23ef8336458251b6ebd5093f91eca0\n  git: {}\n\n\nRun ID: da1 was successful after 4m49s\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': '8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1', 'target': 'automl-compute', 'status': 'Completed', 'startTimeUtc': '2022-06-08T12:35:44.296296Z', 'endTimeUtc': '2022-06-08T12:36:47.605027Z', 'services': {}, 'properties': {'ContentSnapshotId': '1c9c5956-3c85-48e5-8278-a1ad6b778144', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'e6f9b511-7172-4c38-be79-1e81116712b5', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '0d5017c5', 'azureml.pipelinerunid': '6f805508-6544-416f-922c-359c4e0a183f', 'azureml.pipeline': '6f805508-6544-416f-922c-359c4e0a183f', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '31b0dfe2-49dd-4ee9-8f8b-a225c4622f8e'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '9f79d25c-7356-4c46-a631-f306ceab3f04'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"9f79d25c-7356-4c46-a631-f306ceab3f04\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='ml-lab-b4jqaft7eli2q', subscription_id='6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef', resource_group='cal-1087-7c')\"\n  }\n}}], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'automl-compute', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '31b0dfe2-49dd-4ee9-8f8b-a225c4622f8e', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '6f805508-6544-416f-922c-359c4e0a183f', 'azureml.pipelineRun.moduleNodeId': '0d5017c5', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/westcentralus/workspaces/847c158a-f05f-4ebb-8850-171f11997d8d/environments/experiment_env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.8', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=eHtEYH7omDQ9QeD4YIoZCUwO22HAqgwkwz8dDURlqhM%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A24%3A00Z&se=2022-06-08T20%3A34%3A00Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=kgn6HAKgUgZHD5iByrHmbY%2F1JB9poiZu3FzY3duMBNw%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=I3aTzds78vtsx5lc3b47CUajfi6poVFFx7I1P5ZeNDo%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2022-06-08-12': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/dataprep/0/rslex.log.2022-06-08-12?sv=2019-07-07&sr=b&sig=Zf6XnlFUFQowmMdqwPN9ZSvm4WAb%2BNmH3KzhloMmf4Y%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=l%2BUZI2FYAsWwvTciiXkgiUBk9DUrKgNI%2B%2BX5bSdlnfc%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=9PaE6uAnxcdjbbuupMYnipPpVZXm4hxv0bq%2Bdp9OZFc%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=nmgca%2FzArMtB9upZHlvSgXlcjLTcPSxdrTtQBtibhZk%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A45Z&se=2022-06-08T20%3A36%3A45Z&sp=r', 'user_logs/std_log.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=IoNdea%2BUakHCMv0VwgPuBwtLWHZxsgCA4CiY%2BHsz%2B1M%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=0QG3NWaxu0Xphhao8mU3dhM9XiudyZGsSW8iu0Yv2KQ%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=STOZNYik6OMZRKBVWkVRSD4tTynwUTgdC5VS1CtiHeg%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/data_capability/rslex.log.2022-06-08-12': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/data_capability/rslex.log.2022-06-08-12?sv=2019-07-07&sr=b&sig=JLG3RP%2FfxttKfkjmi%2BhZyiyv5C1tUnfJ2tri8owveFQ%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=5RsHGvMfJ2H2VwQTZ2blzvZICTtKFaGLtBqYWydmgkE%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=IVofKmaPgr4Az0YHojxbpQRZr9m0EQDGq8TpP6VSiSA%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=mjyujTkMaoyP74%2FRBhakwKu1sMyoul8cPBIyC1Wz0%2Bc%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.8ab69e6f-46bf-41a3-b39a-29bc0f3d78c1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=aKURwCvBVS4tCa%2BS6J911aL4fMu497UWX2gzTL%2BIcNY%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A50Z&se=2022-06-08T20%3A36%3A50Z&sp=r'}, 'submittedBy': 'student-1087-1272524'}\n\n\n\n\nStepRunId: 0a325487-9e29-46c8-af79-e5d01faac9fa\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/0a325487-9e29-46c8-af79-e5d01faac9fa?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\nStepRun( Train and Register Model ) Status: Running\n\nStepRun(Train and Register Model) Execution Summary\n====================================================\nStepRun( Train and Register Model ) Status: Finished\n{'runId': '0a325487-9e29-46c8-af79-e5d01faac9fa', 'target': 'automl-compute', 'status': 'Completed', 'startTimeUtc': '2022-06-08T12:36:57.15384Z', 'endTimeUtc': '2022-06-08T12:37:10.802738Z', 'services': {}, 'properties': {'ContentSnapshotId': '1c9c5956-3c85-48e5-8278-a1ad6b778144', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'e0bbf26a-f0f8-410b-9b4f-e06b114ca391', 'azureml.moduleName': 'Train and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '7153653e', 'azureml.pipelinerunid': '6f805508-6544-416f-922c-359c4e0a183f', 'azureml.pipeline': '6f805508-6544-416f-922c-359c4e0a183f', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '9f79d25c-7356-4c46-a631-f306ceab3f04'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_358aaeac', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_358aaeac'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'automl-compute', 'dataReferences': {}, 'data': {'input_358aaeac': {'dataLocation': {'dataset': {'id': '9f79d25c-7356-4c46-a631-f306ceab3f04', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_358aaeac', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '1', 'assetId': 'azureml://locations/westcentralus/workspaces/847c158a-f05f-4ebb-8850-171f11997d8d/environments/experiment_env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.8', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220412.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=RjXjXVTE6F4TRla2GaU7jvkjMKnKyZG38o5q7SKINUY%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A55Z&se=2022-06-08T20%3A36%3A55Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=%2Fhyq9%2BTFhOMuZwL1ZUhh93ne8zpX%2FFvcvJ9jFRoUzfo%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A55Z&se=2022-06-08T20%3A36%3A55Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ynYgqt%2FfBpzOZfP199JjnJuiDA%2BnJolE4cdr46fMJKU%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A26%3A55Z&se=2022-06-08T20%3A36%3A55Z&sp=r', 'user_logs/std_log.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=rr4kqkaOSKzKwJ0oFaHTfR5yELUKjE2gRMIuopBS7Eg%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A12Z&se=2022-06-08T20%3A37%3A12Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=fJEcMRGdngnU%2Bijt5rBQDW5wzQkFi8OLV%2F7g202LhDQ%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=%2BkKQqvNY6VHmxMHV1JY8k3LuxSnIvBLENE2TGrMsbSY%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/data_capability/rslex.log.2022-06-08-12': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/data_capability/rslex.log.2022-06-08-12?sv=2019-07-07&sr=b&sig=RzSY6A6vrRpptxqUPAmyUK639smRM81Dk7B%2Bsf%2Bv4yk%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=II8IrzXjAeohvI5q%2B1CfW7Q6ge%2BcW0m4KbAVsefwXcM%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=dHrLJOu329tnn%2BQBa5GepmqdhYrXzxk2a%2FjQqW0lrVA%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=I8xxWSALpCz%2Fsrqi9wucDtoQmS2a%2BCNPOMCWGRn4sIo%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=DGRMRj5KIljlHaw37h4jZS%2BIGZVFkpuHGjE4UOrANKk%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A27%3A13Z&se=2022-06-08T20%3A37%3A13Z&sp=r'}, 'submittedBy': 'student-1087-1272524'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '6f805508-6544-416f-922c-359c4e0a183f', 'status': 'Completed', 'startTimeUtc': '2022-06-08T12:23:06.124634Z', 'endTimeUtc': '2022-06-08T12:37:11.815818Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=F0RfOagKG5rqjjsYbWrBKkrPsicNByZG782M6d4bDLo%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A24%3A27Z&se=2022-06-08T20%3A34%3A27Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=dtsUt4C8%2Bq8qTd1P1GzM%2FmL7QFzVkE7T3aW3vWVH7ps%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A24%3A27Z&se=2022-06-08T20%3A34%3A27Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.6f805508-6544-416f-922c-359c4e0a183f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Zf7YvpyrgcCf3v6bIozSsbb9RZq%2F%2FMvCkHnbd5SK0dY%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A24%3A27Z&se=2022-06-08T20%3A34%3A27Z&sp=r'}, 'submittedBy': 'student-1087-1272524'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1654691834427
        },
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A graphical representation of the pipeline experiment will be displayed in the widget as it runs. Keep an eye on the kernel indicator at the top right of the page, when it turns from **&#9899;** to **&#9711;**, the code has finished running. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "When the pipeline has finished, you can examine the metrics recorded by it's child runs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Train and Register Model :\n\t Accuracy : 0.9\n\t AUC : 0.8849244514913718\n\t ROC : aml://artifactId/ExperimentRun/dcid.0a325487-9e29-46c8-af79-e5d01faac9fa/ROC_1654691825.png\nPrepare Data :\n\t raw_rows : 15000\n\t processed_rows : 15000\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1654691851974
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming the pipeline was successful, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes_model version: 1\n\t Training context : Pipeline\n\t AUC : 0.8849244514913718\n\t Accuracy : 0.9\n\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1654691970238
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish the pipeline\n",
        "\n",
        "After you've created and tested a pipeline, you can publish it as a REST service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-training-pipeline,\nId: 39adb83c-42ea-4efe-a87b-93c6d4bdeb52,\nStatus: Active,\nEndpoint: https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourceGroups/cal-1087-7c/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-b4jqaft7eli2q/PipelineRuns/PipelineSubmit/39adb83c-42ea-4efe-a87b-93c6d4bdeb52)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/39adb83c-42ea-4efe-a87b-93c6d4bdeb52?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q\" target=\"_blank\" rel=\"noopener\">39adb83c-42ea-4efe-a87b-93c6d4bdeb52</a></td><td>Active</td><td><a href=\"https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourceGroups/cal-1087-7c/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-b4jqaft7eli2q/PipelineRuns/PipelineSubmit/39adb83c-42ea-4efe-a87b-93c6d4bdeb52\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1654692016208
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the published pipeline has an endpoint, which you can see in the **Endpoints** page (on the **Pipeline Endpoints** tab) in [Azure Machine Learning studio](https://ml.azure.com). You can also find its URI as a property of the published pipeline object:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://westcentralus.api.azureml.ms/pipelines/v1.0/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourceGroups/cal-1087-7c/providers/Microsoft.MachineLearningServices/workspaces/ml-lab-b4jqaft7eli2q/PipelineRuns/PipelineSubmit/39adb83c-42ea-4efe-a87b-93c6d4bdeb52\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1654692032654
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call the pipeline endpoint\n",
        "\n",
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1654692186796
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "'48738a85-039e-490b-8e98-3c2d4b2e32a1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1654692253723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since you have the run ID, you can use it to wait for the run to complete.\n",
        "\n",
        "> **Note**: The pipeline should complete quickly, because each step was configured to allow output reuse. This was done primarily for convenience and to save time in this course. In reality, you'd likely want the first step to run every time in case the data has changed, and trigger the subsequent steps only if the output from step one changes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 48738a85-039e-490b-8e98-3c2d4b2e32a1\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/48738a85-039e-490b-8e98-3c2d4b2e32a1?wsid=/subscriptions/6d3ddb69-3bd6-4e8d-904c-41cccfb8c9ef/resourcegroups/cal-1087-7c/workspaces/ml-lab-b4jqaft7eli2q&tid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '48738a85-039e-490b-8e98-3c2d4b2e32a1', 'status': 'Completed', 'startTimeUtc': '2022-06-08T12:44:14.666656Z', 'endTimeUtc': '2022-06-08T12:44:16.178288Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineid': '39adb83c-42ea-4efe-a87b-93c6d4bdeb52', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.48738a85-039e-490b-8e98-3c2d4b2e32a1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=srjHPBhGBRvyMqNquCiPMq8RdAzslEoCMBgD6fRL0wk%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A34%3A46Z&se=2022-06-08T20%3A44%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.48738a85-039e-490b-8e98-3c2d4b2e32a1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=tV3Pit0KRDzXHRd1hkhTmTXgR05RzdgZLZqk83Vw%2B2w%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A34%3A46Z&se=2022-06-08T20%3A44%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.48738a85-039e-490b-8e98-3c2d4b2e32a1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=L0koJFQbhW18NHugq%2F7%2FenKKSthdJSGVHpNTpGRww0A%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A34%3A46Z&se=2022-06-08T20%3A44%3A46Z&sp=r'}, 'submittedBy': 'student-1087-1272524'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1654692432723
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule the Pipeline\n",
        "\n",
        "Suppose the clinic for the diabetes patients collects new data each week, and adds it to the dataset. You could run the pipeline every week to retrain the model with the new data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-diabetes-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline scheduled.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1654692499058
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can retrieve the schedules that are defined in the workspace like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "[Pipeline(Name: weekly-diabetes-training,\n Id: 57f04af4-18be-4d1d-9de7-13fc1ce53681,\n Status: Active,\n Pipeline Id: 39adb83c-42ea-4efe-a87b-93c6d4bdeb52,\n Pipeline Endpoint Id: None,\n Recurrence Details: Runs at 0:00 on Monday every Week)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1654692505064
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check the latest run like this:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "{'runId': '820a39c6-8698-48c8-b244-ecd211ad705f',\n 'status': 'Completed',\n 'startTimeUtc': '2022-06-08T12:48:22.158658Z',\n 'endTimeUtc': '2022-06-08T12:48:23.530814Z',\n 'services': {},\n 'properties': {'azureml.runsource': 'azureml.PipelineRun',\n  'runSource': 'Unavailable',\n  'runType': 'Schedule',\n  'azureml.parameters': '{}',\n  'azureml.continue_on_step_failure': 'False',\n  'azureml.pipelineid': '39adb83c-42ea-4efe-a87b-93c6d4bdeb52',\n  'azureml.pipelineComponent': 'pipelinerun'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.820a39c6-8698-48c8-b244-ecd211ad705f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=8cDSTbrXYmIVTGDKY9crKLdDJFhQpUW2CSxWR%2FI54QM%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A38%3A43Z&se=2022-06-08T20%3A48%3A43Z&sp=r',\n  'logs/azureml/stderrlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.820a39c6-8698-48c8-b244-ecd211ad705f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=LlUBxWhZwysBOoAsNmCMxl9xYZgQZug%2FcU35Cbta0nE%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A38%3A43Z&se=2022-06-08T20%3A48%3A43Z&sp=r',\n  'logs/azureml/stdoutlogs.txt': 'https://mllabb4jqaft7eli2q.blob.core.windows.net/azureml/ExperimentRun/dcid.820a39c6-8698-48c8-b244-ecd211ad705f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=RX3jO7OBzCfjouVuVI%2Flpk9ho62MqQWhZUfAJsg9u4c%3D&skoid=4126f8f0-dec3-46d4-af52-ace83c6028ac&sktid=fd1fbf9f-991a-40b4-ae26-61dfc34421ef&skt=2022-06-08T12%3A13%3A04Z&ske=2022-06-09T20%3A23%3A04Z&sks=b&skv=2019-07-07&st=2022-06-08T12%3A38%3A43Z&se=2022-06-08T20%3A48%3A43Z&sp=r'},\n 'submittedBy': 'student-1087-1272524'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1654692523389
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
        "\n",
        "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}